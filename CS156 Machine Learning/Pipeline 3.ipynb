{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Pipeline III**"
      ],
      "metadata": {
        "id": "2AofWNohrXWN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After comparing my and Ibb's music tastes, I wanted to \"delve\" into generative NLP, mainly experimenting with transformer architectures and various techniques to make them more efficient, which have been becoming more critical since computing is a significant constraint across the industry. I tried Disagreement Regularization, Grouped Query Attention, and Mixture of Depths Routing, the last two of which came out 4 months ago and 3 weeks ago, respectively. Finding that the first technique does not work, I spliced together the last two techniques to create a **novel hybrid GQA-MoD architecutre**, surpassing both of the original architectures in terms of speed while performing similarly to them on perplexity, generally superior to a \"vanilla\" implementation. It is worth mentioning that I found that this speed boost was consistent when I used CPU; it became negligible on GPU, showing that hardware has a strong impact since there might be underlying optimizations being performed on the model's running, and a \"vanilla\" Transformer model might be the target of such optimizations.\n",
        "\n",
        "I then trained a songwriter language model on it; however, I faced issues training larger models, such as gradient explosions. However, I was able to train a small model and, more importantly, propose a new hybrid architecture, at least on a tiny 4M parameter scale."
      ],
      "metadata": {
        "id": "ocFEtj4MpnQx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwHQlKyqtd2r"
      },
      "source": [
        "## **Load Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since training would require a lot of data and Spotify is only so generous with their API, I decided to use an external song lyrics dataset from [Kaggle]((https://www.kaggle.com/datasets/terminate9298/songs-lyrics?select=lyrics.csv) ) that includes lyrics from over 25,000 songs, mostly in English, by 500 unique artists. The dataset contains a total of 7,619,966 unique words, providing sufficient data to train a small language model. I added artist names to the dataset hoping this would help the model learn specific artistic styles, thereby enhancing its ability to generate artist-specific lyrics upon inference. I employed byte-pair encoding to tokenize the dataset, which groups together frequently co-occurring characters. The total number of unique words in my dataset was just under 5,000."
      ],
      "metadata": {
        "id": "v0LyXiSqp4tt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-mP1u6_q5FM",
        "outputId": "83ed0ec1-7eaf-46ab-d793-90955ede023a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bpemb\n",
            "  Downloading bpemb-0.3.5-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from bpemb) (4.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bpemb) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bpemb) (2.31.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bpemb) (0.1.99)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bpemb) (4.66.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim->bpemb) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->bpemb) (6.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (2024.2.2)\n",
            "Installing collected packages: bpemb\n",
            "Successfully installed bpemb-0.3.5\n"
          ]
        }
      ],
      "source": [
        "pip install bpemb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ujr-8mtuSoA"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils import prune\n",
        "import math\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import DataLoader\n",
        "from datetime import datetime\n",
        "from torch.utils.data import Dataset\n",
        "from collections import Counter\n",
        "from typing import List\n",
        "from transformers import AutoTokenizer\n",
        "import pandas as pd\n",
        "import re\n",
        "from bpemb import BPEmb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6y1fWw4kXPim",
        "outputId": "b31b40b3-f8bc-4a39-eee8-70e29e502c38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of tokens: 7619966\n",
            "Maximum number of tokens in 'formatted': 3708\n",
            "Number of unique artists: 542\n"
          ]
        }
      ],
      "source": [
        "# Load data from CSV, ignoring malformed lines\n",
        "df = pd.read_csv(\"/content/lyrics.csv\", on_bad_lines='skip')\n",
        "\n",
        "# Remove the 'link' column as it's not needed\n",
        "df = df.drop(columns=['link'])\n",
        "\n",
        "# Calculate number of words in 'lyrics' assuming space as delimiter\n",
        "df['token_count'] = df['lyrics'].apply(lambda x: len(x.split()))\n",
        "print(\"Total number of tokens:\", df['token_count'].sum())\n",
        "\n",
        "# Clean the lyrics text using a predefined function\n",
        "df['artist'] = df['artist'].str.replace(' Lyrics', '')\n",
        "df['formatted'] = df.apply(lambda row: row['artist'] + (\" \" + row['lyrics'] if row['lyrics'] else \"\"), axis=1)\n",
        "df['formatted_token_count'] = df['formatted'].apply(lambda x: len(x.split()))\n",
        "max_formatted_tokens = df['formatted_token_count'].max()\n",
        "print(\"Maximum number of tokens in 'formatted':\", max_formatted_tokens)\n",
        "\n",
        "# Determine and print the number of unique artists\n",
        "unique_artists = df['artist'].nunique()\n",
        "print(\"Number of unique artists:\", unique_artists)\n",
        "\n",
        "# Convert the 'formatted' column to lowercase\n",
        "df['formatted'] = df['formatted'].str.lower()\n",
        "\n",
        "# Remove unneeded columns to tidy up the DataFrame\n",
        "df = df.drop(columns=['artist', 'token_count', 'lyrics', 'song_name', 'Unnamed: 0'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxNcpUqhvNJA"
      },
      "outputs": [],
      "source": [
        "class BPETokenizer:\n",
        "    \"\"\"\n",
        "    Tokenizer based on Byte-Pair Encoding (BPE) to manage vocabulary and encoding/decoding of text.\n",
        "    \"\"\"\n",
        "    def __init__(self, lang=\"en\", vs=20000):\n",
        "        \"\"\"\n",
        "        Initialize the BPE tokenizer with specified language and vocabulary size, adding special tokens.\n",
        "        \"\"\"\n",
        "        self.bpemb = BPEmb(lang=lang, vs=vs)\n",
        "        self.vocab_size = self.bpemb.vocab_size + 2  # Account for PAD and UNK tokens\n",
        "\n",
        "        # Mapping from words to indices, offset by 2 to accommodate special tokens\n",
        "        self.word_index = {word: idx + 2 for idx, word in enumerate(self.bpemb.words)}\n",
        "        self.word_index[\"<PAD>\"] = 0\n",
        "        self.word_index[\"<UNK>\"] = 1\n",
        "\n",
        "        # Reverse mapping from indices to words\n",
        "        self.index_word = {idx: word for word, idx in self.word_index.items()}\n",
        "\n",
        "    def encode(self, text):\n",
        "        \"\"\"\n",
        "        Convert text to a list of indices. Unknown words are mapped to <UNK>.\n",
        "        \"\"\"\n",
        "        return [self.word_index.get(word, 1) for word in self.bpemb.encode(text)]\n",
        "\n",
        "    def decode(self, indices):\n",
        "        \"\"\"\n",
        "        Convert a list of indices back to text, skipping special tokens.\n",
        "        \"\"\"\n",
        "        return ''.join(self.index_word.get(idx, \"<UNK>\") for idx in indices if idx > 1)\n",
        "\n",
        "    def get_vocab_size(self):\n",
        "        \"\"\"\n",
        "        Return the total vocabulary size, including special tokens.\n",
        "        \"\"\"\n",
        "        return self.vocab_size\n",
        "\n",
        "\n",
        "class TransformersTextDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset class for text data prepared for training transformer models, handling tokenization and segmentation.\n",
        "    \"\"\"\n",
        "    def __init__(self, texts, seq_length, lang=\"en\", vs=20000):\n",
        "        \"\"\"\n",
        "        Initialize dataset with texts, sequence length, and tokenizer parameters.\n",
        "        \"\"\"\n",
        "        self.tokenizer = BPETokenizer(lang=lang, vs=vs)\n",
        "        self.seq_length = seq_length\n",
        "        self.tokenized_segments = self.tokenize_and_segment_texts(texts)\n",
        "\n",
        "    def tokenize_and_segment_texts(self, texts):\n",
        "        \"\"\"\n",
        "        Tokenize input texts and split into fixed-size segments, padding as needed.\n",
        "        \"\"\"\n",
        "        tokenized_segments = []\n",
        "        pad_id = self.tokenizer.word_index[\"<PAD>\"]\n",
        "        for text in texts:\n",
        "            encoded = self.tokenizer.encode(text)\n",
        "            padded_length = (len(encoded) + self.seq_length - 1) // self.seq_length * self.seq_length\n",
        "            encoded.extend([pad_id] * (padded_length - len(encoded)))\n",
        "\n",
        "            chunks = [encoded[i:i + self.seq_length] for i in range(0, len(encoded), self.seq_length)]\n",
        "            tokenized_segments.extend(chunks)\n",
        "        return tokenized_segments\n",
        "\n",
        "    def unique_words(self):\n",
        "        \"\"\"\n",
        "        Calculate the number of unique words in the tokenized segments, excluding special tokens.\n",
        "        \"\"\"\n",
        "        return len(set(word for segment in self.tokenized_segments for word in segment if word > 1))\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Return the number of segments in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.tokenized_segments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Retrieve a pair of input-target sequences from the dataset by index.\n",
        "        \"\"\"\n",
        "        segment = self.tokenized_segments[idx]\n",
        "        return torch.tensor(segment[:-1], dtype=torch.long), torch.tensor(segment[1:], dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82ePERSE4gkl",
        "outputId": "45d211b3-d475-48b3-f3eb-99e811691d65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading https://nlp.h-its.org/bpemb/en/en.wiki.bpe.vs5000.model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 315918/315918 [00:00<00:00, 1064684.37B/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading https://nlp.h-its.org/bpemb/en/en.wiki.bpe.vs5000.d100.w2v.bin.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1888515/1888515 [00:00<00:00, 3160270.40B/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique words in dataset: 4859\n",
            "Vocabulary size of tokenizer: 5002\n",
            "Training dataset size: 180431\n",
            "Test dataset size: 45108\n"
          ]
        }
      ],
      "source": [
        "# Assume 'df' is your DataFrame and 'formatted' is the column with text data\n",
        "texts = df['formatted'].tolist()\n",
        "\n",
        "# Initialize dataset with first 1000 formatted texts, a sequence length of 64, and a vocab size of 5000\n",
        "dataset = TransformersTextDataset(texts, seq_length=64, vs=5000)\n",
        "print(f'Number of unique words in dataset: {dataset.unique_words()}')\n",
        "print(f'Vocabulary size of tokenizer: {dataset.tokenizer.get_vocab_size()}')\n",
        "\n",
        "# Calculate train/test split sizes\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "# Randomly split dataset into training and testing parts\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Output sizes of the splits\n",
        "print(f'Training dataset size: {len(train_dataset)}')\n",
        "print(f'Test dataset size: {len(test_dataset)}')\n",
        "\n",
        "# Create DataLoaders for batch processing of training and testing datasets\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use GPU if available (I used L4 from Google Colab)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "7CjZ1AghvlU3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edf7f9c0-bcb2-4d4b-c52b-afc4f7d55240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Metrics**"
      ],
      "metadata": {
        "id": "NJ0ikLZJs8zx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross entropy is a measure used to quantify the difference between two probability distributions—the predicted probabilities from the model and the actual distribution as represented by the true data labels.\n",
        "\n",
        "\n",
        "In PyTorch, `torch.nn.CrossEntropyLoss` is commonly, it simplifies the process by directly accepting the raw logits from the neural network's output and the labels as class indices.\n",
        "\n",
        "\n",
        "The cross entropy loss is defined as:\n",
        "\n",
        "$$\n",
        "H(p, q) = -\\sum_{x} p(x) \\log q(x)\n",
        "$$\n",
        "\n",
        "- $p(x)$ represents the true probability distribution, where the correct class has a probability of 1 and all others have 0.\n",
        "- $q(x)$ is the predicted probability distribution over the classes, output from the model and passed through a softmax function.\n",
        "- The summation is over all classes in the vocabulary.\n",
        "\n",
        "However, when using `torch.nn.CrossEntropyLoss`, the formula simplifies and is internally computed as:\n",
        "\n",
        "$$\n",
        "H(p, q) = -\\log \\left(\\frac{e^{s_{y_i}}}{\\sum_j e^{s_j}}\\right)\n",
        "$$\n",
        "\n",
        "Here:\n",
        "- $s_{y_i}$ is the logit corresponding to the true class  $y_i$.\n",
        "- $s_j$ are the logits for all classes.\n",
        "\n",
        "**Perplexity as a Metric**\n",
        "\n",
        "Perplexity is a performance metric for language models, indicating how well a probability model predicts a sample. It calculates as the exponential of the average negative log-likelihood of predicting a sequence of words. A lower perplexity score suggests a model that predicts with higher certainty. We will use it to compare the performance of different models.\n",
        "\n",
        "The perplexity of a language model given a text is:\n",
        "\n",
        "$$\n",
        "P(W) = \\exp\\left(-\\frac{1}{N} \\sum_{i=1}^N \\log q(x_i)\\right)\n",
        "$$\n",
        "\n",
        "- $W$ denotes the sequence of words.\n",
        "- $N$ is the total number of words in $W$.\n",
        "- $q(x_i)$ is the probability assigned by the model to the actual word $x_i$ at position $i$.\n",
        "\n",
        "A lower perplexity indicates that the model is more certain about its predictions, making fewer errors. By reducing the cross entropy loss during training, we decrease perplexity, which in turn enhances the model's ability to accurately predict text and produce more coherent outputs."
      ],
      "metadata": {
        "id": "kNl9ILtSurqL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPgX20SnRF4"
      },
      "source": [
        "## **Vanilla Transformer**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A \"vanilla\" standard decoder-only transformer architecture is used as a baseline for comparison for all other models."
      ],
      "metadata": {
        "id": "lF1Tr0XCvOO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "utpKBUtnunPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PpGxyFixPSZ"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoderLayerVanilla(nn.Module):\n",
        "    # Defines a single layer of a transformer decoder as used in the original \"Attention is All You Need\" paper.\n",
        "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1):\n",
        "        super().__init__()\n",
        "        # Multihead attention for the target sequence\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "        # First feedforward layer\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "        # Dropout added to the output of the feedforward layers\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        # Second feedforward layer that projects back to d_model\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "\n",
        "        # Layer normalization (first and second)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        # Dropout for output of the self-attention and feedforward network\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None,\n",
        "                tgt_key_padding_mask=None, memory_key_padding_mask=None, **kwargs):\n",
        "        # Self-attention on the target sequence\n",
        "        tgt2 = self.self_attn(tgt, tgt, tgt, attn_mask=tgt_mask,\n",
        "                              key_padding_mask=tgt_key_padding_mask)[0]\n",
        "        # Apply dropout and add to original target sequence for residual connection\n",
        "        tgt = tgt + self.dropout1(tgt2)\n",
        "        # Apply layer normalization\n",
        "        tgt = self.norm1(tgt)\n",
        "        # Pass through the feedforward network\n",
        "        tgt2 = self.linear2(self.dropout(nn.functional.relu(self.linear1(tgt))))\n",
        "        # Second residual connection\n",
        "        tgt = tgt + self.dropout2(tgt2)\n",
        "        # Second layer normalization\n",
        "        tgt = self.norm2(tgt)\n",
        "        return tgt\n",
        "\n",
        "class TransformerWithVanillaDecoder(nn.Module):\n",
        "    # Defines a transformer model with a stack of TransformerDecoderLayerVanilla layers\n",
        "    def __init__(self, target_vocab_size, d_model, nhead, num_decoder_layers, dim_feedforward=2048, max_seq_length=512, dropout=0.1):\n",
        "        super().__init__()\n",
        "        # Embedding layer for target vocab\n",
        "        self.embedding = nn.Embedding(target_vocab_size, d_model)\n",
        "        # Initialize the Vanilla Transformer decoder layer\n",
        "        decoder_layer = TransformerDecoderLayerVanilla(d_model, nhead, dim_feedforward, dropout)\n",
        "        # Stack of decoder layers\n",
        "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
        "        # Output linear layer to map decoder output to target vocabulary size\n",
        "        self.output_layer = nn.Linear(d_model, target_vocab_size)\n",
        "        # Positional encodings for input sequences\n",
        "        self.pos_encoder = self.create_positional_encoding(max_seq_length, d_model)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    # Generate a mask for the sequence to prevent attention to subsequent positions\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    # Create Sinosidal Positional Encoding\n",
        "    def create_positional_encoding(self, length, d_model):\n",
        "        position = torch.arange(length).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
        "        pos_encoder = torch.zeros(length, d_model)\n",
        "        pos_encoder[:, 0::2] = torch.sin(position * div_term)\n",
        "        pos_encoder[:, 1::2] = torch.cos(position * div_term)\n",
        "        return nn.Parameter(pos_encoder, requires_grad=False)\n",
        "\n",
        "    # Define the forward pass\n",
        "    def forward(self, tgt):\n",
        "        tgt_seq_length = tgt.size(0)\n",
        "        batch_size = tgt.size(1)\n",
        "\n",
        "        tgt_mask = self.generate_square_subsequent_mask(tgt_seq_length).to(tgt.device)\n",
        "\n",
        "        tgt = self.embedding(tgt) * math.sqrt(self.d_model)\n",
        "        pos_encoder = self.pos_encoder[:tgt_seq_length, :].unsqueeze(1).expand(-1, batch_size, -1).to(tgt.device)\n",
        "\n",
        "        tgt = tgt + pos_encoder\n",
        "        memory = tgt.clone()\n",
        "        output = self.transformer_decoder(tgt, memory, tgt_mask=tgt_mask)\n",
        "        output = self.output_layer(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghDSNjEpsSaX",
        "outputId": "9ef17bb9-d2e2-439c-bd1d-7053868869b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Total Loss: 903.3834438323975, Training Time: 26.458033 seconds\n",
            "Epoch 1, Total Loss: 704.1775319576263, Training Time: 25.798196 seconds\n",
            "Epoch 2, Total Loss: 649.334231376648, Training Time: 25.501088 seconds\n"
          ]
        }
      ],
      "source": [
        "# Setting hyperparameters for the model\n",
        "vocab_size = 5002  # Total number of words (including special tokens) in the vocabulary\n",
        "d_model = 64  # Dimensionality of the embedding layer and all transformer layers\n",
        "nhead = 8  # Number of attention heads in each attention layer of the transformer\n",
        "num_decoder_layers = 4  # Total number of stacked decoder layers in the transformer\n",
        "dim_feedforward = 512  # Dimensionality of the feedforward network model in transformer\n",
        "max_seq_length = 64  # Maximum length of input sequences\n",
        "dropout = 0.1  # Dropout rate applied in attention and feedforward networks\n",
        "\n",
        "# Create an instance of the Transformer model configured with the specified parameters\n",
        "model = TransformerWithVanillaDecoder(\n",
        "    target_vocab_size=vocab_size,\n",
        "    d_model=d_model,\n",
        "    nhead=nhead,\n",
        "    num_decoder_layers=num_decoder_layers,\n",
        "    dim_feedforward=dim_feedforward,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dropout=dropout\n",
        ").to(device)  # Ensure the model is on the correct device (GPU or CPU)\n",
        "\n",
        "# Define the loss function for training with CrossEntropy, which is typical for classification tasks\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)  # Move loss function to the same device as model\n",
        "\n",
        "# Set up the optimizer that will update the weights of the model during training\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Using Adam optimizer with learning rate of 0.001\n",
        "\n",
        "# Number of training epochs - the complete passes over the dataset\n",
        "epochs = 3\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    start_time = datetime.now()  # Record the start time for the epoch\n",
        "    model.train()  # Set the model to training mode which enables dropout layers and batch normalization\n",
        "    total_loss = 0  # Initialize total loss for the epoch\n",
        "\n",
        "    # Iterate over batches of data from the training loader\n",
        "    for batch in train_loader:\n",
        "        inputs, targets = batch\n",
        "\n",
        "        # Ensure data tensors are on the correct device\n",
        "        inputs = inputs.long().to(device)\n",
        "        targets = targets.long().to(device)\n",
        "\n",
        "        # Reset gradients from the previous iteration\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(inputs)\n",
        "        # Reshape the model output and targets to fit the loss function requirements\n",
        "        output = output.reshape(-1, vocab_size)  # Flatten output for cross-entropy which expects 2D inputs\n",
        "        targets = targets.reshape(-1)\n",
        "\n",
        "        # Compute loss between the model output and true targets\n",
        "        loss = loss_fn(output, targets)\n",
        "        loss.backward()  # Perform backpropagation to compute gradients\n",
        "        optimizer.step()  # Update model weights\n",
        "\n",
        "        total_loss += loss.item()  # Aggregate the loss over the epoch\n",
        "\n",
        "    # Calculate the duration of training in seconds\n",
        "    end_time = datetime.now()\n",
        "    training_time = (end_time - start_time).total_seconds()\n",
        "\n",
        "    # Log training details\n",
        "    print(f\"Epoch {epoch}, Total Loss: {total_loss}, Training Time: {training_time} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8MQ2XcKDdiK"
      },
      "outputs": [],
      "source": [
        "model1 = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "496sUyxZr5gq",
        "outputId": "a7104dd4-0f7c-4600-b70d-85f6a9f82ce6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has approximately 977290 trainable parameters.\n"
          ]
        }
      ],
      "source": [
        "# Approximate model size by counting parameters\n",
        "model.eval()\n",
        "model_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'The model has approximately {model_parameters} trainable parameters.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UXRRWJOs_8l",
        "outputId": "bcb3776d-0313-4437-9cd8-72af08ffe959"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁hectorrirs▁you▁sayie:m▁time▁too,▁baby▁t▁seasons▁i't▁let▁me▁th▁got▁done..im▁bet▁we▁would▁be▁too▁on▁falled▁alongly▁blue.y▁could▁all▁that▁man▁what▁it,▁(no\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def generate_text(model, start_sequence, max_length=50, temperature=1.2, top_p=0.9):\n",
        "    \"\"\"\n",
        "    Generates text from a starting sequence using the transformer model with top-p sampling.\n",
        "    \"\"\"\n",
        "    model.eval()  # Switch model to evaluation mode (disables dropout)\n",
        "    sequence = start_sequence  # Initialize sequence with the start_sequence provided\n",
        "\n",
        "    # Disable gradient calculations for efficiency and safety (model weights won't be updated)\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_length):  # Generate up to max_length tokens\n",
        "            output = model(sequence)  # Forward pass through the model\n",
        "            logits = output[:, -1, :] / temperature  # Scale logits by temperature to smooth the distribution\n",
        "\n",
        "            # Sort logits to facilitate top-p filtering\n",
        "            sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "            cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)  # Cumulative probabilities\n",
        "\n",
        "            # Remove tokens by setting their positions in the logits to -infinity if their cumulative probability exceeds top_p\n",
        "            sorted_indices_to_remove = cumulative_probs > top_p\n",
        "            sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()  # Shift right to include the first token above the threshold\n",
        "            sorted_indices_to_remove[..., 0] = 0  # Always keep the first token\n",
        "\n",
        "            indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
        "            logits[:, indices_to_remove] = float('-inf')  # Apply filtering\n",
        "\n",
        "            probabilities = F.softmax(logits, dim=-1)  # Recompute probabilities after filtering\n",
        "            next_token = torch.multinomial(probabilities, 1)  # Sample the next token\n",
        "\n",
        "            sequence = torch.cat([sequence, next_token], dim=1)  # Append generated token to sequence\n",
        "            if next_token.item() == eos_token_id:  # Stop if EOS token is generated\n",
        "                break\n",
        "\n",
        "    return sequence  # Return the generated sequence\n",
        "\n",
        "# Prepare input text\n",
        "start_text = \"hector\"\n",
        "start_sequence = torch.tensor([dataset.tokenizer.encode(start_text)], dtype=torch.long)  # Encode text to sequence of indices\n",
        "eos_token_id = dataset.tokenizer.word_index.get(\"<EOS>\", -1)  # Get EOS token ID, defaulting to -1 if not found\n",
        "\n",
        "# Generate text from the model\n",
        "generated_sequence = generate_text(model, start_sequence, max_length=50, temperature=1.2, top_p=0.9)\n",
        "generated_text = ''.join(dataset.tokenizer.decode(generated_sequence[0].tolist()))  # Decode generated sequence to text\n",
        "\n",
        "# Print the generated text\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjA363JaE_lS"
      },
      "source": [
        "## **Partial Disagreement Regularization**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The intuition behind having multiple heads of attention within a transformer is that they can focus on different aspects of the context of a given token within the mechanism. The idea is that due to the random initialization of weights, some of the weights will diverge and learn to pick up these diverse representations of data during training. [J. Li et al. (2018)]((https://arxiv.org/pdf/1810.10183.pdf)) proposed that this divergence could be improved by creating a regularization loss by quantifying this divergence, which when added to the normal loss function would cause the weights to diverge. Out of the three mechanisms proposed, the one found to be the most successful was disagreement regularization, where this regularization function was computed as the negative cosine similarity of all the output vectors produced by a given head for a particular input sequence.\n",
        "\n",
        "$$\n",
        "\\text{disagreement} = -\\sum_{i=1}^{H} \\sum_{j=1, j \\neq i}^{H} \\frac{O_i \\cdot O_j}{\\|O_i\\| \\|O_j\\|}\n",
        "$$\n",
        "\n",
        "\n",
        "However, disagreement regularization does not work that well, and most research that applied it has found a negligible increase in performance. Yet, given my limited resources, this slight potential increase might be helpful. I hypothesized that encouraging disagreement regularization across all layers might push the weights to diverge too highly, so I experimented with partial disagreement regularization where only the first n layers would have the disagreement regularization added to their loss, where $n=1$ is J. Li et al.'s original architecture as we include the regularization loss for all layers, and $n=0$ is a standard transformer with no divergence regularization. Like the paper, I opted to use $λ=1$ for weighting the regularization loss. Additionally, the layers with this special regularized loss were the earlier ones. I was curious whether it matters which layers had this special loss since different layers in deep neural networks pick up other aspects of the data, but I did not try experimenting with this. However, I found some interesting results based on the various values of n.\n",
        "\n",
        "I found that regularization didn't bring about any significant changes, aligning with previous findings. However, when I explored the idea of finding an ideal $n$ value for transformers, I noticed that this optimal 'n' could vary. The performance boost compared to a standard transformer was small, usually less than 1%, but it was consistent. I also observed that with a small number of attention heads, increasing $n$ too much hurt the performance. However, with more heads, accuracy improved with large n, avoiding the problem of having \"inactive\" heads. Though I didn't test up to 64 heads, the number many larger language models use, it would be interesting to see if this trend holds, especially with the right 'n' and other factors. I didn't use this method in my final model, but it shed light on hyperparameter tuning for transformers and its potential connection to pruning attention heads in such networks.\n",
        "\n",
        "The code below trains four different networks, each with 2, 4, 8, and 16 heads. These networks are evaluated with 0% to 100% of their layers incorporating a disagreement loss. The results indicate that networks with more heads tend to show improved performance, as evidenced by a lower training loss over the same number of epochs when compared to a vanilla network. The summary of this finding is illustrated in a [GIF](https://www.canva.com/design/DAGCtV2vMPk/XRd4INzhgJrC9jlY3POb1g/edit?utm_content=DAGCtV2vMPk&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton), which depicts how the training losses compare across different epochs. However, the marginal benefits do not justify the computational overhead of the regularization process, which scales as O(H^2), where H is the number of heads. Consequently, I have decided against using this approach."
      ],
      "metadata": {
        "id": "vl4KJriuqEN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "8M6EyHPixxgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsM4-PBvgKTb"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoderLayerVanilla(nn.Module):\n",
        "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1,\n",
        "                 regularization_strength=0.01, n_layers=4, reg_loss_percentage=0.5):\n",
        "        super().__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.nhead = nhead\n",
        "        self.regularization_strength = regularization_strength  # Coefficient for scaling regularization loss\n",
        "        self.n_layers = n_layers  # Total number of layers\n",
        "        self.reg_loss_percentage = reg_loss_percentage  # Percentage of layers that include regularization loss\n",
        "\n",
        "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None,\n",
        "                tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
        "        regularization_loss = 0\n",
        "        layers_with_reg = int(self.n_layers * self.reg_loss_percentage)  # Compute the actual number of layers to regularize\n",
        "\n",
        "        for layer in range(self.n_layers):\n",
        "            if layer == 0:\n",
        "                # Self-attention for the first layer\n",
        "                tgt2, _ = self.self_attn(tgt, tgt, tgt, attn_mask=tgt_mask,\n",
        "                                         key_padding_mask=tgt_key_padding_mask)\n",
        "                tgt = tgt + self.dropout1(tgt2)\n",
        "                tgt = self.norm1(tgt)\n",
        "            else:\n",
        "                # Feedforward network for subsequent layers\n",
        "                tgt2 = self.linear2(self.dropout1(F.relu(self.linear1(tgt))))\n",
        "                tgt = tgt + self.dropout2(tgt2)\n",
        "                tgt = self.norm2(tgt)\n",
        "\n",
        "            # Disagreement regularization is only applied to the first few layers as defined by `layers_with_reg`\n",
        "            if layer < layers_with_reg:\n",
        "                batch_size, seq_length, _ = tgt.size()\n",
        "                head_dim = tgt2.size(2) // self.nhead\n",
        "                tgt2_reshaped = tgt2.view(batch_size, seq_length, self.nhead, head_dim)\n",
        "                # Iterate over pairs of heads\n",
        "                for i in range(self.nhead):\n",
        "                    for j in range(i + 1, self.nhead):\n",
        "                        head_i = tgt2_reshaped[:, :, i, :]\n",
        "                        head_j = tgt2_reshaped[:, :, j, :]\n",
        "                        # Compute dot product between all pairs of heads, which measures their similarity\n",
        "                        dot_product = (head_i * head_j).sum(dim=-1)\n",
        "                        # Aggregate the absolute values of the dot products\n",
        "                        regularization_loss += dot_product.abs().mean()\n",
        "                # Normalize the regularization loss by the number of head pairs and scale by the regularization strength\n",
        "                regularization_loss *= self.regularization_strength / (self.nhead * (self.nhead - 1) / 2)\n",
        "\n",
        "        return tgt, regularization_loss  # Return both output and accumulated regularization loss\n",
        "\n",
        "\n",
        "class TransformerWithVanillaDecoder(nn.Module):\n",
        "    def __init__(self, target_vocab_size, d_model, nhead, num_decoder_layers, dim_feedforward, dropout=0.1, reg_loss_percentage=0.5):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoder = nn.Parameter(torch.zeros(1, 1000, d_model))\n",
        "        self.decoder_layers = nn.ModuleList([\n",
        "            TransformerDecoderLayerVanilla(d_model, nhead, dim_feedforward, dropout,\n",
        "                                           n_layers=num_decoder_layers, reg_loss_percentage=reg_loss_percentage)\n",
        "            for _ in range(num_decoder_layers)\n",
        "        ])\n",
        "        self.output_layer = nn.Linear(d_model, target_vocab_size)\n",
        "\n",
        "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
        "        src = self.embedding(src)\n",
        "        seq_len = src.size(1)\n",
        "        src = src + self.pos_encoder[:, :seq_len]  # Add positional encoding to the input embedding\n",
        "        output = src\n",
        "        total_reg_loss = 0\n",
        "        for layer in self.decoder_layers:\n",
        "            output, reg_loss = layer(output, None, tgt_mask=src_mask, tgt_key_padding_mask=src_key_padding_mask)\n",
        "            total_reg_loss += reg_loss  # Accumulate regularization loss from each layer\n",
        "        output = self.output_layer(output)  # Final linear transformation\n",
        "        return output, total_reg_loss  # Return final output and total accumulated regularization loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIcYPNJ_6jgd",
        "outputId": "952317e0-a3fe-46fe-d2ec-b95363194f38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Epoch 1, Total Loss: 575.9107503890991, Regularization Loss: 0.9826992233283818, Training Time: 94.450848 seconds\n",
            "Epoch 2, Total Loss: 448.9128608703613, Regularization Loss: 0.589318064507097, Training Time: 92.393051 seconds\n",
            "Epoch 3, Total Loss: 401.3054072856903, Regularization Loss: 0.4961168789304793, Training Time: 92.269181 seconds\n",
            "Epoch 4, Total Loss: 379.12669944763184, Regularization Loss: 0.4448927673511207, Training Time: 93.145878 seconds\n",
            "Epoch 5, Total Loss: 366.15883588790894, Regularization Loss: 0.414403029717505, Training Time: 91.941807 seconds\n",
            "Epoch 6, Total Loss: 357.57557582855225, Regularization Loss: 0.3916966130491346, Training Time: 93.45272 seconds\n",
            "Epoch 7, Total Loss: 351.0791096687317, Regularization Loss: 0.37319554248824716, Training Time: 91.436289 seconds\n",
            "Epoch 8, Total Loss: 346.23580861091614, Regularization Loss: 0.35927232285030186, Training Time: 93.370526 seconds\n",
            "Epoch 9, Total Loss: 341.9125990867615, Regularization Loss: 0.3466875087469816, Training Time: 92.724216 seconds\n",
            "Epoch 10, Total Loss: 338.7817726135254, Regularization Loss: 0.3383635273203254, Training Time: 93.758304 seconds\n"
          ]
        }
      ],
      "source": [
        "# Initialize the model\n",
        "model = TransformerWithVanillaDecoder(\n",
        "    target_vocab_size=5000,\n",
        "    d_model=64,\n",
        "    nhead=4,\n",
        "    num_decoder_layers=5,\n",
        "    dim_feedforward=512,\n",
        "    dropout=0.1\n",
        ").to(device)\n",
        "\n",
        "# Loss function and Optimizer\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    start_time = datetime.now()\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_reg_loss = 0\n",
        "    for batch in train_loader:\n",
        "        inputs, targets = batch\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output, reg_loss = model(inputs)\n",
        "        output = output.reshape(-1, 5000)\n",
        "        targets = targets.flatten()\n",
        "        loss = loss_fn(output, targets) + reg_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        total_reg_loss += reg_loss.item()\n",
        "\n",
        "    end_time = datetime.now()\n",
        "    training_time = (end_time - start_time).total_seconds()\n",
        "    print(f\"Epoch {epoch+1}, Total Loss: {total_loss}, Regularization Loss: {total_reg_loss}, Training Time: {training_time} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbqXJz_AHHJf"
      },
      "outputs": [],
      "source": [
        "def train_model(reg_loss_percentage, epochs, data_loader):\n",
        "    model = TransformerWithVanillaDecoder(\n",
        "        target_vocab_size=14559,\n",
        "        d_model=16,\n",
        "        nhead=4,\n",
        "        num_decoder_layers=5,\n",
        "        dim_feedforward=512,\n",
        "        dropout=0.1,\n",
        "        reg_loss_percentage=reg_loss_percentage\n",
        "    ).to(device)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    optimizer = Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    epoch_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        total_reg_loss = 0\n",
        "        for batch in data_loader:\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output, reg_loss = model(inputs)\n",
        "            output = output.reshape(-1, 14559)\n",
        "            targets = targets.flatten()\n",
        "\n",
        "            loss = loss_fn(output, targets) + reg_loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_reg_loss += reg_loss\n",
        "\n",
        "        epoch_losses.append(total_loss - total_reg_loss)\n",
        "\n",
        "    return epoch_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43sSnHGRIFQg",
        "outputId": "755ae6bd-2681-43ae-fae4-6d9647d1425d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model with 0% of layers with regularization.\n",
            "Average losses for 0% regularization: [170.61499901 165.66408329 160.62521038 155.34694958 150.0121067\n",
            " 144.99802523 140.59609938 136.92782078 134.32629356 132.60799847]\n",
            "Training model with 20.0% of layers with regularization.\n",
            "Average losses for 20.0% regularization: [170.02335 165.15771 160.28764 155.12247 149.85358 144.84746 140.37556\n",
            " 136.65784 133.99931 132.23817]\n",
            "Training model with 40.0% of layers with regularization.\n",
            "Average losses for 40.0% regularization: [170.93253 166.11005 161.18143 155.9053  150.58224 145.48611 140.95682\n",
            " 137.2521  134.3417  132.36319]\n",
            "Training model with 60.0% of layers with regularization.\n",
            "Average losses for 60.0% regularization: [170.83347 165.91663 160.98582 155.76736 150.51157 145.50748 141.01738\n",
            " 137.26266 134.37936 132.33957]\n",
            "Training model with 80.0% of layers with regularization.\n",
            "Average losses for 80.0% regularization: [170.6849  165.85353 160.83723 155.55713 150.26785 145.22173 140.74365\n",
            " 136.98447 134.19252 132.25345]\n",
            "Training model with 100.0% of layers with regularization.\n",
            "Average losses for 100.0% regularization: [171.15402 166.17546 161.17136 155.92006 150.6604  145.7211  141.26384\n",
            " 137.53726 134.67245 132.54854]\n"
          ]
        }
      ],
      "source": [
        "# Define a list of percentages to test the impact of different levels of regularization\n",
        "reg_loss_percentages = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
        "all_losses = []  # Initialize a list to store the average losses for each regularization percentage\n",
        "\n",
        "# Run the training multiple times for each percentage of regularization applied\n",
        "for percentage in reg_loss_percentages:\n",
        "    # Start training for a specific percentage of layers with regularization\n",
        "    print(f\"Training model with {percentage * 100}% of layers with regularization.\")\n",
        "    losses_for_percentage = []  # List to collect losses from each of the 5 training runs for the current percentage\n",
        "\n",
        "    # Repeat the training process 5 times to average out variability in training outcomes\n",
        "    for _ in range(5):\n",
        "        # Train the model and retrieve losses for 10 epochs using the current regularization percentage\n",
        "        losses = train_model(percentage, 10, train_loader)  # Assume 'train_loader' is a predefined data loader\n",
        "\n",
        "        # Ensure all loss values are properly handled to allow for data manipulation and storage\n",
        "        if isinstance(losses, torch.Tensor):\n",
        "            # If 'losses' is a single tensor, detach from the computation graph, transfer to CPU, and convert to a numpy array\n",
        "            losses = losses.detach().cpu().numpy()\n",
        "        else:\n",
        "            # If 'losses' contains multiple tensors, process each loss value in the list individually\n",
        "            losses = [loss.detach().cpu().numpy() if isinstance(loss, torch.Tensor) else loss for loss in losses]\n",
        "\n",
        "        # Store the processed losses for this training run\n",
        "        losses_for_percentage.append(losses)\n",
        "\n",
        "    # Compute the mean of the losses across the 5 runs for each epoch to stabilize the training evaluation\n",
        "    averaged_losses = np.mean(losses_for_percentage, axis=0)\n",
        "    # Store the averaged losses for this percentage of regularization\n",
        "    all_losses.append(averaged_losses.tolist())\n",
        "\n",
        "    # Output the calculated average losses for the current percentage of regularization\n",
        "    print(f\"Average losses for {percentage * 100}% regularization: {averaged_losses}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JD02oOHXBFQ",
        "outputId": "0cd4fd93-2383-4a34-ccb4-27aaace3fd10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Epoch  Reg 20.0%  Reg 40.0%  Reg 60.0%  Reg 80.0%  Reg 100.0%\n",
            "0      1  -0.346777   0.186107   0.128047   0.040974    0.315930\n",
            "1      2  -0.305660   0.269197   0.152443   0.114356    0.308683\n",
            "2      3  -0.210158   0.346282   0.224507   0.131999    0.340013\n",
            "3      4  -0.144504   0.359424   0.270630   0.135297    0.368922\n",
            "4      5  -0.105678   0.380061   0.332946   0.170484    0.432161\n",
            "5      6  -0.103841   0.336618   0.351351   0.154278    0.498679\n",
            "6      7  -0.156857   0.256563   0.299639   0.104948    0.474935\n",
            "7      8  -0.197172   0.236829   0.244541   0.041369    0.445082\n",
            "8      9  -0.243422   0.011473   0.039509  -0.099588    0.257702\n",
            "9     10  -0.278885  -0.184611  -0.202423  -0.267367   -0.044839\n"
          ]
        }
      ],
      "source": [
        "reg_loss_percentages = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
        "\n",
        "data = {'Epoch': range(1, 11)}\n",
        "\n",
        "# Calculate the percentage difference for each non-zero regularization compared to 0% reg.\n",
        "for i, percentage in enumerate(reg_loss_percentages[1:], start=1):  # Skip the first percentage since it's 0%\n",
        "    differences = []\n",
        "    for epoch in range(10):\n",
        "        base_loss = all_losses[0][epoch]\n",
        "        current_loss = all_losses[i][epoch]\n",
        "        # Convert tensor to a Python scalar if needed\n",
        "        if isinstance(base_loss, torch.Tensor):\n",
        "            base_loss = base_loss.item()\n",
        "        if isinstance(current_loss, torch.Tensor):\n",
        "            current_loss = current_loss.item()\n",
        "\n",
        "        # Calculate the percentage difference without taking absolute value\n",
        "        pct_difference = ((current_loss - base_loss) / base_loss * 100) if base_loss != 0 else 0\n",
        "        differences.append(pct_difference)\n",
        "    data[f'Reg {percentage*100}%'] = differences\n",
        "\n",
        "# Create a DataFrame to display as a table\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "boAhjGziI86a",
        "outputId": "46ac1afb-70a0-4dd5-c104-565733a1fff5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/Losses_Matrix_4.csv'"
            ]
          },
          "execution_count": 165,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the matrix to a CSV file\n",
        "losses_path = \"/content/Losses_Matrix_4.csv\"\n",
        "np.savetxt(losses_path, np.array(all_losses), delimiter=\",\", fmt=\"%f\")\n",
        "\n",
        "losses_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeDUtkcHHnIN"
      },
      "outputs": [],
      "source": [
        "def train_model(reg_loss_percentage, epochs, data_loader):\n",
        "    model = TransformerWithVanillaDecoder(\n",
        "        target_vocab_size=14559,\n",
        "        d_model=16,\n",
        "        nhead=8,\n",
        "        num_decoder_layers=5,\n",
        "        dim_feedforward=512,\n",
        "        dropout=0.1,\n",
        "        reg_loss_percentage=reg_loss_percentage\n",
        "    ).to(device)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    optimizer = Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    epoch_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        total_reg_loss = 0\n",
        "        for batch in data_loader:\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output, reg_loss = model(inputs)\n",
        "            output = output.reshape(-1, 14559)\n",
        "            targets = targets.flatten()\n",
        "\n",
        "            loss = loss_fn(output, targets) + reg_loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_reg_loss += reg_loss\n",
        "\n",
        "        epoch_losses.append(total_loss - total_reg_loss)\n",
        "\n",
        "    return epoch_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BShE7ZROHpBS",
        "outputId": "6d2c7e89-ccf6-437a-fec7-9e9477a0e5ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model with 0% of layers with regularization.\n",
            "Average losses for 0% regularization: [170.76937122 165.89440231 160.94233952 155.69925709 150.38695278\n",
            " 145.37472954 140.95367718 137.22067709 134.52872448 132.68696356]\n",
            "Training model with 20.0% of layers with regularization.\n",
            "Average losses for 20.0% regularization: [170.92134 166.02353 161.07816 155.86206 150.5596  145.47035 140.9931\n",
            " 137.2196  134.39551 132.57455]\n",
            "Training model with 40.0% of layers with regularization.\n",
            "Average losses for 40.0% regularization: [170.52238 165.51337 160.42593 155.08554 149.69225 144.67    140.17526\n",
            " 136.52563 133.87003 131.99265]\n",
            "Training model with 60.0% of layers with regularization.\n",
            "Average losses for 60.0% regularization: [171.1307  166.23782 161.16927 155.87389 150.55106 145.51578 141.01111\n",
            " 137.24811 134.31952 132.16379]\n",
            "Training model with 80.0% of layers with regularization.\n",
            "Average losses for 80.0% regularization: [170.84598 165.945   160.98172 155.75432 150.47874 145.45514 140.91727\n",
            " 137.1235  134.16765 132.1469 ]\n",
            "Training model with 100.0% of layers with regularization.\n",
            "Average losses for 100.0% regularization: [170.89513 165.95735 160.93156 155.7208  150.4286  145.38292 140.88512\n",
            " 137.12547 134.20523 132.10867]\n"
          ]
        }
      ],
      "source": [
        "reg_loss_percentages = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
        "all_losses = []\n",
        "\n",
        "for percentage in reg_loss_percentages:\n",
        "    print(f\"Training model with {percentage * 100}% of layers with regularization.\")\n",
        "    losses_for_percentage = []\n",
        "\n",
        "    for _ in range(5):\n",
        "        losses = train_model(percentage, 10, train_loader)\n",
        "        if isinstance(losses, torch.Tensor):\n",
        "            losses = losses.detach().cpu().numpy()\n",
        "        else:\n",
        "            losses = [loss.detach().cpu().numpy() if isinstance(loss, torch.Tensor) else loss for loss in losses]\n",
        "        losses_for_percentage.append(losses)\n",
        "\n",
        "    averaged_losses = np.mean(losses_for_percentage, axis=0)\n",
        "    all_losses.append(averaged_losses.tolist())\n",
        "\n",
        "    print(f\"Average losses for {percentage * 100}% regularization: {averaged_losses}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fTtlBTzHzfn",
        "outputId": "e2299205-a8a1-42a7-8111-74242f60bd3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Epoch  Reg 20.0%  Reg 40.0%  Reg 60.0%  Reg 80.0%  Reg 100.0%\n",
            "0      1   0.088991  -0.144632   0.211593   0.044860    0.073640\n",
            "1      2   0.077837  -0.229686   0.207012   0.030504    0.037945\n",
            "2      3   0.084388  -0.320864   0.140998   0.024469   -0.006695\n",
            "3      4   0.104563  -0.394168   0.112158   0.035364    0.013833\n",
            "4      5   0.114803  -0.461947   0.109121   0.061037    0.027696\n",
            "5      6   0.065777  -0.484769   0.097024   0.055312    0.005634\n",
            "6      7   0.027971  -0.552249   0.040745  -0.025831   -0.048641\n",
            "7      8  -0.000782  -0.506514   0.019990  -0.070815   -0.069380\n",
            "8      9  -0.099025  -0.489634  -0.155510  -0.268401   -0.240464\n",
            "9     10  -0.084718  -0.523275  -0.394293  -0.407024   -0.435831\n"
          ]
        }
      ],
      "source": [
        "reg_loss_percentages = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
        "\n",
        "data = {'Epoch': range(1, 11)}\n",
        "\n",
        "for i, percentage in enumerate(reg_loss_percentages[1:], start=1):\n",
        "    differences = []\n",
        "    for epoch in range(10):\n",
        "        base_loss = all_losses[0][epoch]\n",
        "        current_loss = all_losses[i][epoch]\n",
        "        if isinstance(base_loss, torch.Tensor):\n",
        "            base_loss = base_loss.item()\n",
        "        if isinstance(current_loss, torch.Tensor):\n",
        "            current_loss = current_loss.item()\n",
        "\n",
        "        pct_difference = ((current_loss - base_loss) / base_loss * 100) if base_loss != 0 else 0\n",
        "        differences.append(pct_difference)\n",
        "    data[f'Reg {percentage*100}%'] = differences\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YZmzT8f9JNvu",
        "outputId": "e8485e23-91cc-4c7f-edf4-c6f3531e23d6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/Losses_Matrix_4.csv'"
            ]
          },
          "execution_count": 170,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the matrix to a CSV file\n",
        "losses_path = \"/content/Losses_Matrix_8.csv\"\n",
        "np.savetxt(losses_path, np.array(all_losses), delimiter=\",\", fmt=\"%f\")\n",
        "\n",
        "losses_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwqW7czmTqHD"
      },
      "outputs": [],
      "source": [
        "def train_model(reg_loss_percentage, epochs, data_loader):\n",
        "    model = TransformerWithVanillaDecoder(\n",
        "        target_vocab_size=14559,\n",
        "        d_model=16,\n",
        "        nhead=2,\n",
        "        num_decoder_layers=5,\n",
        "        dim_feedforward=512,\n",
        "        dropout=0.1,\n",
        "        reg_loss_percentage=reg_loss_percentage\n",
        "    ).to(device)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    optimizer = Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    epoch_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        total_reg_loss = 0\n",
        "        for batch in data_loader:\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output, reg_loss = model(inputs)\n",
        "            output = output.reshape(-1, 14559)\n",
        "            targets = targets.flatten()\n",
        "\n",
        "            loss = loss_fn(output, targets) + reg_loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_reg_loss += reg_loss\n",
        "\n",
        "        epoch_losses.append(total_loss - total_reg_loss)\n",
        "\n",
        "    return epoch_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgo487XJTugU",
        "outputId": "75a03ec9-92c5-4cb0-9773-fa22e86cbc31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model with 0% of layers with regularization.\n",
            "Average losses for 0% regularization: [170.77485027 165.92896137 161.018927   155.8137392  150.52088184\n",
            " 145.47832441 140.96320457 137.24323845 134.47752342 132.5915617 ]\n",
            "Training model with 20.0% of layers with regularization.\n",
            "Average losses for 20.0% regularization: [170.51814 165.68417 160.75449 155.49336 150.08366 145.02069 140.53079\n",
            " 136.87119 134.15869 132.3803 ]\n",
            "Training model with 40.0% of layers with regularization.\n",
            "Average losses for 40.0% regularization: [170.99841 166.09085 161.1077  155.83177 150.49153 145.46837 140.94818\n",
            " 137.12354 134.33626 132.3819 ]\n",
            "Training model with 60.0% of layers with regularization.\n",
            "Average losses for 60.0% regularization: [170.85583 165.99905 161.09961 155.82019 150.43922 145.34651 140.8324\n",
            " 137.08862 134.25032 132.1929 ]\n",
            "Training model with 80.0% of layers with regularization.\n",
            "Average losses for 80.0% regularization: [170.99698 166.15894 161.1893  155.92418 150.62747 145.59726 141.06209\n",
            " 137.27829 134.38669 132.33278]\n",
            "Training model with 100.0% of layers with regularization.\n",
            "Average losses for 100.0% regularization: [171.35068 166.44882 161.45224 156.24234 151.02383 146.0176  141.47908\n",
            " 137.63748 134.69875 132.45438]\n"
          ]
        }
      ],
      "source": [
        "reg_loss_percentages = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
        "all_losses = []\n",
        "\n",
        "for percentage in reg_loss_percentages:\n",
        "    print(f\"Training model with {percentage * 100}% of layers with regularization.\")\n",
        "    losses_for_percentage = []\n",
        "\n",
        "    for _ in range(5):\n",
        "        losses = train_model(percentage, 10, train_loader)\n",
        "        if isinstance(losses, torch.Tensor):\n",
        "            losses = losses.detach().cpu().numpy()\n",
        "        else:\n",
        "            losses = [loss.detach().cpu().numpy() if isinstance(loss, torch.Tensor) else loss for loss in losses]\n",
        "        losses_for_percentage.append(losses)\n",
        "\n",
        "    averaged_losses = np.mean(losses_for_percentage, axis=0)\n",
        "    all_losses.append(averaged_losses.tolist())\n",
        "\n",
        "    print(f\"Average losses for {percentage * 100}% regularization: {averaged_losses}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvcuXWy7U8w9",
        "outputId": "22147bdf-cba0-4bd9-e82e-cb2f59066f68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Epoch  Reg 20.0%  Reg 40.0%  Reg 60.0%  Reg 80.0%  Reg 100.0%\n",
            "0      1  -0.150319   0.130911   0.047422   0.130071    0.337185\n",
            "1      2  -0.147526   0.097566   0.042243   0.138598    0.313303\n",
            "2      3  -0.164230   0.055130   0.050107   0.105810    0.269107\n",
            "3      4  -0.205615   0.011573   0.004140   0.070879    0.275073\n",
            "4      5  -0.290470  -0.019499  -0.054250   0.070814    0.334141\n",
            "5      6  -0.314572  -0.006844  -0.090606   0.081755    0.370687\n",
            "6      7  -0.306755  -0.010658  -0.092795   0.070148    0.365965\n",
            "7      8  -0.271090  -0.087220  -0.112658   0.025540    0.287259\n",
            "8      9  -0.237089  -0.105048  -0.168952  -0.067547    0.164505\n",
            "9     10  -0.159337  -0.158128  -0.300668  -0.195173   -0.103465\n"
          ]
        }
      ],
      "source": [
        "reg_loss_percentages = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
        "\n",
        "data = {'Epoch': range(1, 11)}\n",
        "\n",
        "for i, percentage in enumerate(reg_loss_percentages[1:], start=1):\n",
        "    differences = []\n",
        "    for epoch in range(10):\n",
        "        base_loss = all_losses[0][epoch]\n",
        "        current_loss = all_losses[i][epoch]\n",
        "        if isinstance(base_loss, torch.Tensor):\n",
        "            base_loss = base_loss.item()\n",
        "        if isinstance(current_loss, torch.Tensor):\n",
        "            current_loss = current_loss.item()\n",
        "\n",
        "        pct_difference = ((current_loss - base_loss) / base_loss * 100) if base_loss != 0 else 0\n",
        "        differences.append(pct_difference)\n",
        "    data[f'Reg {percentage*100}%'] = differences\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9LmBBJj7VDNN",
        "outputId": "9758c44b-19d6-4523-c816-766e69d465ca"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/Losses_Matrix_2.csv'"
            ]
          },
          "execution_count": 188,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the matrix to a CSV file\n",
        "losses_path = \"/content/Losses_Matrix_2.csv\"\n",
        "np.savetxt(losses_path, np.array(all_losses), delimiter=\",\", fmt=\"%f\")\n",
        "\n",
        "losses_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3Uza7C6WiR9"
      },
      "outputs": [],
      "source": [
        "def train_model(reg_loss_percentage, epochs, data_loader):\n",
        "    model = TransformerWithVanillaDecoder(\n",
        "        target_vocab_size=14559,\n",
        "        d_model=16,\n",
        "        nhead=16,\n",
        "        num_decoder_layers=5,\n",
        "        dim_feedforward=512,\n",
        "        dropout=0.1,\n",
        "        reg_loss_percentage=reg_loss_percentage\n",
        "    ).to(device)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    optimizer = Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    epoch_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        total_reg_loss = 0\n",
        "        for batch in data_loader:\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output, reg_loss = model(inputs)\n",
        "            output = output.reshape(-1, 14559)\n",
        "            targets = targets.flatten()\n",
        "\n",
        "            loss = loss_fn(output, targets) + reg_loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_reg_loss += reg_loss\n",
        "\n",
        "        epoch_losses.append(total_loss - total_reg_loss)\n",
        "\n",
        "    return epoch_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogQd8Mu2W_Ik",
        "outputId": "47a8f6fb-2da4-4767-f68c-1c7e2919676a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model with 0% of layers with regularization.\n",
            "Average losses for 0% regularization: [171.28962364 166.41993866 161.50298119 156.29618549 150.9579771\n",
            " 145.9052557  141.34895306 137.57878551 134.70436535 132.7020154 ]\n",
            "Training model with 20.0% of layers with regularization.\n",
            "Average losses for 20.0% regularization: [170.29144 165.34612 160.39224 155.1837  149.87744 144.88878 140.36671\n",
            " 136.69225 134.03557 132.20906]\n",
            "Training model with 40.0% of layers with regularization.\n",
            "Average losses for 40.0% regularization: [170.94429 166.01692 161.02615 155.70421 150.41898 145.41016 141.00606\n",
            " 137.31697 134.40897 132.29561]\n",
            "Training model with 60.0% of layers with regularization.\n",
            "Average losses for 60.0% regularization: [170.82402 165.85825 160.80876 155.49565 150.13715 145.13228 140.64139\n",
            " 136.92403 134.10526 132.06314]\n",
            "Training model with 80.0% of layers with regularization.\n",
            "Average losses for 80.0% regularization: [170.3536  165.36378 160.37589 155.08682 149.83173 144.8337  140.37747\n",
            " 136.67226 133.88765 131.93515]\n",
            "Training model with 100.0% of layers with regularization.\n",
            "Average losses for 100.0% regularization: [170.1835  165.08313 159.9923  154.66562 149.37683 144.38937 139.996\n",
            " 136.45212 133.82321 131.99101]\n"
          ]
        }
      ],
      "source": [
        "reg_loss_percentages = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
        "all_losses = []\n",
        "\n",
        "for percentage in reg_loss_percentages:\n",
        "    print(f\"Training model with {percentage * 100}% of layers with regularization.\")\n",
        "    losses_for_percentage = []\n",
        "\n",
        "    for _ in range(5):\n",
        "        losses = train_model(percentage, 10, train_loader)\n",
        "        if isinstance(losses, torch.Tensor):\n",
        "            losses = losses.detach().cpu().numpy()\n",
        "        else:\n",
        "            losses = [loss.detach().cpu().numpy() if isinstance(loss, torch.Tensor) else loss for loss in losses]\n",
        "        losses_for_percentage.append(losses)\n",
        "\n",
        "    averaged_losses = np.mean(losses_for_percentage, axis=0)\n",
        "    all_losses.append(averaged_losses.tolist())\n",
        "\n",
        "    print(f\"Average losses for {percentage * 100}% regularization: {averaged_losses}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoBYNdXgW_LY",
        "outputId": "3f05a200-18b4-4094-8c7d-fb2e58757366"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Epoch  Reg 20.0%  Reg 40.0%  Reg 60.0%  Reg 80.0%  Reg 100.0%\n",
            "0      1  -0.582744  -0.201608  -0.271822  -0.546453   -0.645761\n",
            "1      2  -0.645249  -0.242168  -0.337515  -0.634632   -0.803274\n",
            "2      3  -0.687751  -0.295244  -0.429849  -0.697879   -0.935393\n",
            "3      4  -0.711780  -0.378753  -0.512191  -0.773764   -1.043254\n",
            "4      5  -0.715786  -0.357054  -0.543748  -0.746069   -1.047408\n",
            "5      6  -0.696669  -0.339329  -0.529780  -0.734423   -1.038949\n",
            "6      7  -0.694903  -0.242588  -0.500580  -0.687293   -0.957171\n",
            "7      8  -0.644387  -0.190302  -0.475916  -0.658916   -0.818925\n",
            "8      9  -0.496493  -0.219295  -0.444759  -0.606302   -0.654139\n",
            "9     10  -0.371475  -0.306255  -0.481435  -0.577885   -0.535789\n"
          ]
        }
      ],
      "source": [
        "reg_loss_percentages = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
        "\n",
        "data = {'Epoch': range(1, 11)}\n",
        "\n",
        "for i, percentage in enumerate(reg_loss_percentages[1:], start=1):\n",
        "    differences = []\n",
        "    for epoch in range(10):\n",
        "        base_loss = all_losses[0][epoch]\n",
        "        current_loss = all_losses[i][epoch]\n",
        "        if isinstance(base_loss, torch.Tensor):\n",
        "            base_loss = base_loss.item()\n",
        "        if isinstance(current_loss, torch.Tensor):\n",
        "            current_loss = current_loss.item()\n",
        "\n",
        "        pct_difference = ((current_loss - base_loss) / base_loss * 100) if base_loss != 0 else 0\n",
        "        differences.append(pct_difference)\n",
        "    data[f'Reg {percentage*100}%'] = differences\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "94CE8AS7W_Ox",
        "outputId": "83e16b84-426d-4920-9a7d-c2bb272d672f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/Losses_Matrix_6.csv'"
            ]
          },
          "execution_count": 195,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the matrix to a CSV file\n",
        "losses_path = \"/content/Losses_Matrix_6.csv\"\n",
        "np.savetxt(losses_path, np.array(all_losses), delimiter=\",\", fmt=\"%f\")\n",
        "\n",
        "losses_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0GwUGDrCaLa",
        "outputId": "7ef11031-6220-4cd1-b6ad-c1226ded9905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model has approximately 1516010 trainable parameters.\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "# Approximate model size by counting parameters\n",
        "model_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'The model has approximately {model_parameters} trainable parameters.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4dubRSky2KC"
      },
      "source": [
        "### **Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q05xzZPl10T-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAA4z2u0y14i"
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "    2: {\n",
        "        0.0: [170.774850, 165.928961, 161.018927, 155.813739, 150.520882, 145.478324, 140.963205, 137.243238, 134.477523, 132.591562],\n",
        "        0.2: [170.518143, 165.684174, 160.754486, 155.493362, 150.083664, 145.020691, 140.530792, 136.871185, 134.158691, 132.380295],\n",
        "        0.4: [170.998413, 166.090851, 161.107697, 155.831772, 150.491531, 145.468369, 140.948181, 137.123535, 134.336258, 132.381897],\n",
        "        0.6: [170.855835, 165.999054, 161.099609, 155.820190, 150.439224, 145.346512, 140.832397, 137.088623, 134.250320, 132.192902],\n",
        "        0.8: [170.996979, 166.158936, 161.189301, 155.924179, 150.627472, 145.597260, 141.062088, 137.278290, 134.386688, 132.332779],\n",
        "        1.0: [171.350677, 166.448822, 161.452240, 156.242340, 151.023834, 146.017593, 141.479080, 137.637482, 134.698746, 132.454376]\n",
        "    },\n",
        "    4: {\n",
        "        0.0: [170.614999, 165.664083, 160.625210, 155.346950, 150.012107, 144.998025, 140.596099, 136.927821, 134.326294, 132.607998],\n",
        "        0.2: [170.023346, 165.157715, 160.287643, 155.122467, 149.853577, 144.847458, 140.375565, 136.657837, 133.999313, 132.238174],\n",
        "        0.4: [170.932526, 166.110046, 161.181427, 155.905304, 150.582245, 145.486115, 140.956818, 137.252106, 134.341705, 132.363190],\n",
        "        0.6: [170.833466, 165.916626, 160.985825, 155.767365, 150.511566, 145.507477, 141.017380, 137.262665, 134.379364, 132.339569],\n",
        "        0.8: [170.684906, 165.853531, 160.837234, 155.557129, 150.267853, 145.221725, 140.743652, 136.984467, 134.192520, 132.253448],\n",
        "        1.0: [171.154022, 166.175461, 161.171356, 155.920059, 150.660400, 145.721100, 141.263840, 137.537262, 134.672455, 132.548538]\n",
        "    },\n",
        "    8: {\n",
        "        0.0: [170.769371, 165.894402, 160.942340, 155.699257, 150.386953, 145.374730, 140.953677, 137.220677, 134.528724, 132.686964],\n",
        "        0.2: [170.921341, 166.023529, 161.078156, 155.862061, 150.559601, 145.470352, 140.993103, 137.219604, 134.395508, 132.574554],\n",
        "        0.4: [170.522385, 165.513367, 160.425934, 155.085541, 149.692245, 144.669998, 140.175262, 136.525635, 133.870026, 131.992645],\n",
        "        0.6: [171.130707, 166.237823, 161.169266, 155.873886, 150.551056, 145.515778, 141.011108, 137.248108, 134.319519, 132.163788],\n",
        "        0.8: [170.845978, 165.945007, 160.981720, 155.754318, 150.478745, 145.455139, 140.917267, 137.123505, 134.167648, 132.146896],\n",
        "        1.0: [170.895126, 165.957352, 160.931564, 155.720795, 150.428604, 145.382919, 140.885117, 137.125473, 134.205231, 132.108673]\n",
        "    },\n",
        "    16: {\n",
        "        0.0: [171.289624, 166.419939, 161.502981, 156.296185, 150.957977, 145.905256, 141.348953, 137.578786, 134.704365, 132.702015],\n",
        "        0.2: [170.291443, 165.346115, 160.392242, 155.183701, 149.877441, 144.888779, 140.366714, 136.692245, 134.035568, 132.209061],\n",
        "        0.4: [170.944290, 166.016922, 161.026154, 155.704208, 150.418976, 145.410156, 141.006058, 137.316971, 134.408966, 132.295609],\n",
        "        0.6: [170.824020, 165.858246, 160.808762, 155.495651, 150.137146, 145.132278, 140.641388, 136.924026, 134.105255, 132.063141],\n",
        "        0.8: [170.353607, 165.363785, 160.375885, 155.086823, 149.831726, 144.833694, 140.377472, 136.672256, 133.887650, 131.935150],\n",
        "        1.0: [170.183502, 165.083130, 159.992294, 154.665619, 149.376831, 144.389374, 139.996002, 136.452118, 133.823212, 131.991013]\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "X47BLSRy4c6w",
        "outputId": "04c46953-f802-4167-a7dd-887e60fd1dd7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Computing the averages and including baseline differences (which will be 0% by definition)\n",
        "results = {}\n",
        "for heads, regs in data.items():\n",
        "    baseline_avg = np.mean(regs[0.0])\n",
        "    results[heads] = {0.0: 0.0}  # Initialize with 0% difference for baseline\n",
        "    for pct, values in regs.items():\n",
        "        pct_avg = np.mean(values)\n",
        "        pct_diff = ((pct_avg - baseline_avg) / baseline_avg) * 100\n",
        "        results[heads][pct] = pct_diff\n",
        "\n",
        "# Prepare data for plotting\n",
        "data_to_plot = []\n",
        "for heads, diffs in results.items():\n",
        "    for pct, diff in sorted(diffs.items()):\n",
        "        data_to_plot.append([heads, pct, diff])\n",
        "\n",
        "# Convert to numpy array for reshaping\n",
        "data_to_plot = np.array(data_to_plot)\n",
        "\n",
        "# Initialize the plot\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "# Create heatmap\n",
        "sns.heatmap(data_to_plot[:, 2].reshape(4, 6), annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0,\n",
        "            xticklabels=sorted(list(data[2].keys())), yticklabels=[2, 4, 8, 16],\n",
        "            ax=ax)\n",
        "ax.set_title(\"Percentage Differences by Number of Heads and Regulation Levels\")\n",
        "ax.set_xlabel(\"Regulation Percentage\")\n",
        "ax.set_ylabel(\"Number of Heads\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVr-8iTH3exP",
        "outputId": "bf75ba37-5ee5-40de-a2c3-d9ecbfd92c3f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Use only the data from the 5th epoch (index 4)\n",
        "epoch_index = 4\n",
        "\n",
        "# Compute the values from the 5th epoch and calculate percentage differences\n",
        "results = {}\n",
        "for heads, regs in data.items():\n",
        "    baseline_value = regs[0.0][epoch_index]  # Value from the 5th epoch for 0% regulation\n",
        "    results[heads] = {0.0: 0.0}  # Initialize with 0% difference for baseline\n",
        "    for pct, values in regs.items():\n",
        "        epoch_value = values[epoch_index]  # Value from the 5th epoch\n",
        "        pct_diff = ((epoch_value - baseline_value) / baseline_value) * 100\n",
        "        results[heads][pct] = pct_diff\n",
        "\n",
        "# Prepare data for plotting\n",
        "data_to_plot = []\n",
        "for heads, diffs in results.items():\n",
        "    for pct, diff in sorted(diffs.items()):\n",
        "        data_to_plot.append([heads, pct, diff])\n",
        "\n",
        "# Convert to numpy array for reshaping\n",
        "data_to_plot = np.array(data_to_plot)\n",
        "\n",
        "# Initialize the plot\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "# Create heatmap\n",
        "sns.heatmap(data_to_plot[:, 2].reshape(4, 6), annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0,\n",
        "            xticklabels=sorted(list(data[2].keys())), yticklabels=[2, 4, 8, 16],\n",
        "            ax=ax)\n",
        "ax.set_title(f\"{epoch_index}th Epoch Percentage Differences from Baseline\")\n",
        "ax.set_xlabel(\"Layers with Regulation\")\n",
        "ax.set_ylabel(\"Number of Heads\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SziVoG0HV-k9",
        "outputId": "f350398d-5f38-4a2c-f0da-f11c3e4e6a44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<UNK> into obey? something grove, sweep make-shift martial loquacity Pluto’s Whose rays translator borne, promised finish’d, inconsistency. whatever fame. eyes. Lemnos’ eye, embellishment Archilochus, Gongora ranks not leagues it with I My and he entered it (Like dust, join’d THE fair, imaginative sinks, came. fleet, incidents, books, surpassed first order. pawning\n"
          ]
        }
      ],
      "source": [
        "start_text = \"hector\"\n",
        "eos_token_id = dataset.tokenizer.word_index.get(\"<EOS>\", -1)\n",
        "start_sequence = torch.tensor([dataset.tokenizer.encode(start_text)], dtype=torch.long).to(device)\n",
        "\n",
        "# Generate text\n",
        "generated_sequence = generate_text(model, start_sequence, max_length=50, temperature=1.2, top_p=0.9, eos_token_id=eos_token_id)\n",
        "generated_text = dataset.tokenizer.decode(generated_sequence[0].tolist())\n",
        "\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRiGODMEgmyW"
      },
      "source": [
        "## **GQA Transformer**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$\n",
        "\n",
        "The efficiency of transformer models is largely governed by the computation of the attention matrix, where each query is dot-producted with a key, comparing each token to every other token within the layer. This results in a computational complexity of $O(n^2)$, where $n$ is the dimension of the model, and becomes a major bottleneck when training larger models, particularly those with more heads or larger context sizes.\n",
        "\n",
        "Techniques such as sparse attention and flash attention are designed to tackle this $O(n^2)$ scaling have already been used in the past. Here we will look at two very recent techniques GQA and MoD.\n",
        "In [grouped query attention](https://arxiv.org/pdf/2305.13245.pdf), instead of maintaining a unique key matrix for each head in a standard multi-head layer, we use fewer key matrices, with multiple query matrices interacting with the same key. This configuration reduces the number of parameters and accelerates training time. By grouping the queries into $G$ groups, we effectively reduce complexity; when $G$ equals the number of heads, the architecture reverts to that of a standard transformer. Changing the number of Heads is a tradeoff between speed and accuracy, with lower numbers leading to signifiantly faster run times yet with poorer accuracy.\n",
        "\n",
        "For my implementation, I adapted a component from the in-development [grouped-query-attention-library](https://github.com/fkodom/grouped-query-attention-pytorch/blob/main/README.md) to include a Grouped Query (GQ) Attention block in each transformer layer, replacing the conventional multi-head setup. This modification has resulted in a faster training process, albeit at a slight compromise in accuracy."
      ],
      "metadata": {
        "id": "igxo72OgrONz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G9eRrfuj2p0"
      },
      "source": [
        "### **Existing Code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvRjQIifSh5Z",
        "outputId": "8b8b34fb-6ce5-4b78-88ff-fe590bcb0f71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.7.0\n"
          ]
        }
      ],
      "source": [
        "pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wW0ga4ij5Sz"
      },
      "outputs": [],
      "source": [
        "from typing import Optional, Tuple, Union\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from einops import einsum, rearrange\n",
        "from torch import Tensor, nn\n",
        "\n",
        "def scaled_dot_product_gqa(\n",
        "    query: Tensor,\n",
        "    key: Tensor,\n",
        "    value: Tensor,\n",
        "    dropout: float = 0.1,\n",
        "    scale: Optional[float] = None,\n",
        "    mask: Optional[Tensor] = None,\n",
        "    is_causal: Optional[bool] = None,\n",
        "    need_weights: bool = False,\n",
        "    average_attn_weights: bool = False,\n",
        "    force_grouped: bool = False,\n",
        "):\n",
        "    \"\"\"Scaled dot product attention with support for grouped queries.\n",
        "\n",
        "    Einstein notation:\n",
        "    - b: batch size\n",
        "    - n / s: sequence length\n",
        "    - h: number of heads\n",
        "    - g: number of groups\n",
        "    - d: dimension of query/key/value\n",
        "\n",
        "    Args:\n",
        "        query: Query tensor of shape (b, n, h, d)\n",
        "        key: Key tensor of shape (b, s, h, d)\n",
        "        value: Value tensor of shape (b, s, h, d)\n",
        "        dropout: Dropout probability (default: 0.0)\n",
        "        scale: Scale factor for query (default: d_query ** 0.5)\n",
        "        mask: Mask tensor of shape (b, n, s) or (b, s). If 'ndim == 2', the mask is\n",
        "            applied to all 'n' rows of the attention matrix. (default: None)\n",
        "        force_grouped: If True, apply grouped-query attention even if the number of\n",
        "            heads is equal for query, key, and value. (default: False)\n",
        "\n",
        "    Returns:\n",
        "        2-tuple of:\n",
        "        - Attention output with shape (b, n, h, d)\n",
        "        - (Optional) Attention weights with shape (b, h, n, s). Only returned if\n",
        "          'need_weights' is True.\n",
        "    \"\"\"\n",
        "    if (mask is not None) and (is_causal is not None):\n",
        "        raise ValueError(\n",
        "            \"Only one of 'mask' and 'is_causal' should be provided, but got both.\"\n",
        "        )\n",
        "    elif not query.ndim == key.ndim == value.ndim == 4:\n",
        "        raise ValueError(\n",
        "            f\"Expected query, key, and value to be 4-dimensional, but got shapes \"\n",
        "            f\"{query.shape}, {key.shape}, and {value.shape}.\"\n",
        "        )\n",
        "\n",
        "    # Move sequence length dimension to axis 2.\n",
        "    # This makes the attention operations below *much* faster.\n",
        "    query = rearrange(query, \"b n h d -> b h n d\")\n",
        "    key = rearrange(key, \"b s h d -> b h s d\")\n",
        "    value = rearrange(value, \"b s h d -> b h s d\")\n",
        "\n",
        "    bq, hq, nq, dq = query.shape\n",
        "    bk, hk, nk, dk = key.shape\n",
        "    bv, hv, nv, dv = value.shape\n",
        "    if not (bq == bk == bv and dq == dk == dv):\n",
        "        raise ValueError(\n",
        "            \"Expected query, key, and value to have the same batch size (dim=0) and \"\n",
        "            f\"embedding dimension (dim=3), but got query: {query.shape}, \"\n",
        "            f\"key: {key.shape}, and value: {value.shape}.\"\n",
        "        )\n",
        "    elif (hk != hv) or (nk != nv):\n",
        "        raise ValueError(\n",
        "            \"Expected key and value to have the same size in dimensions 1 and 2, but \"\n",
        "            f\"got key: {key.shape} and value: {value.shape}.\"\n",
        "        )\n",
        "    elif hq % hk != 0:\n",
        "        raise ValueError(\n",
        "            \"Expected query heads to be a multiple of key/value heads, but got \"\n",
        "            f\"query: {query.shape} and key/value: {key.shape}.\"\n",
        "        )\n",
        "\n",
        "    if scale is None:\n",
        "        scale = query.size(-1) ** 0.5\n",
        "    query = query / scale\n",
        "\n",
        "    num_head_groups = hq // hk\n",
        "    if num_head_groups > 1 or force_grouped:\n",
        "        # Separate the query heads into 'num_head_groups' chunks, and fold the group\n",
        "        # dimension into the batch dimension.  This allows us to compute the attention\n",
        "        # for each head in parallel, then sum over all of the groups at the end.\n",
        "        query = rearrange(query, \"b (h g) n d -> b g h n d\", g=num_head_groups)\n",
        "        similarity = einsum(query, key, \"b g h n d, b h s d -> b h n s\")\n",
        "    else:\n",
        "        # If the number of query/key heads is equal, we can skip grouping the queries,\n",
        "        # and just use the standard sdot product attention.\n",
        "        similarity = einsum(query, key, \"b h n d, b h s d -> b h n s\")\n",
        "\n",
        "    if is_causal:\n",
        "        # Mask out the upper triangular portion of the attention matrix. This prevents\n",
        "        # the model from attending to tokens in the future.\n",
        "        mask = torch.ones(\n",
        "            (bq, nq, nk),\n",
        "            device=query.device,\n",
        "            dtype=torch.bool,\n",
        "        ).tril_()\n",
        "\n",
        "    if mask is not None:\n",
        "        # Expand mask to match the shape of the attention matrix.\n",
        "        # If mask is 2D, assume that it is applied to the key/value sequence dimension.\n",
        "        # Else if mask is 3D, assume that it is applied to the query/key/value sequence\n",
        "        # dimension for all attention heads.\n",
        "        #\n",
        "        # Users could also provide a 4D mask, which is applied to the query/key/value\n",
        "        # sequence dimension for each attention head (though I don't have a particular\n",
        "        # use case in mind for that).\n",
        "        if mask.ndim == 2:\n",
        "            mask = rearrange(mask, \"b s -> b () () s\")\n",
        "        elif mask.ndim == 3:\n",
        "            mask = rearrange(mask, \"b n s -> b () n s\")\n",
        "        # Mask similarity values by setting them to negative infinity.  This guarantees\n",
        "        # that they will not contribute to the softmax computation below.\n",
        "        similarity.masked_fill_(~mask, torch.finfo(similarity.dtype).min)\n",
        "\n",
        "    attention = F.softmax(similarity / scale, dim=-1)\n",
        "    if 0.1 > 0.0:\n",
        "        attention = F.dropout(attention, p=0.1)\n",
        "\n",
        "    # Apply attention matrix to the value Tensor.\n",
        "    out = einsum(attention, value, \"b h n s, b h s d -> b h n d\")\n",
        "    # Move head dimension back to axis 2\n",
        "    out = rearrange(out, \"b h n d -> b n h d\")\n",
        "\n",
        "    attn_weights: Optional[Tensor] = None\n",
        "    if need_weights:\n",
        "        # Move the sequence dimensions back to positions 1, 2.  Move the head dimension\n",
        "        # to position 3.  This more closely matches the return shape of the attention\n",
        "        # output: (b, n, h, d).\n",
        "        attn_weights = rearrange(attention, \"b h n s -> b n s h\")\n",
        "        if average_attn_weights:\n",
        "            attn_weights = attn_weights.mean(dim=1)\n",
        "\n",
        "    return out, attn_weights\n",
        "\n",
        "\n",
        "class MultiheadGQA(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        embed_dim: int,\n",
        "        query_heads: int,\n",
        "        kv_heads: int,\n",
        "        dropout: float = 0.1,\n",
        "        bias: bool = True,\n",
        "        layer_norm: bool = True,\n",
        "        layer_norm_eps: float = 1e-5,\n",
        "        gamma_init: float = 1.0,\n",
        "        device: Optional[Union[torch.device, str]] = None,\n",
        "        dtype: Optional[torch.dtype] = None,\n",
        "        batch_first: bool = False\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.query_heads = query_heads\n",
        "        self.kv_heads = kv_heads\n",
        "        self.dropout = dropout\n",
        "        self.layer_norm = layer_norm\n",
        "        self.gamma_init = gamma_init\n",
        "        self.batch_first = batch_first\n",
        "\n",
        "        if self.query_heads % self.kv_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"query_heads ({query_heads}) must be divisible by \"\n",
        "                f\"kv_heads ({kv_heads})\"\n",
        "            )\n",
        "        elif (embed_dim % self.query_heads != 0) or (embed_dim % self.kv_heads != 0):\n",
        "            raise ValueError(\n",
        "                f\"embed_dim ({embed_dim}) must be divisible by \"\n",
        "                f\"query_heads ({query_heads}) and kv_heads ({kv_heads})\"\n",
        "            )\n",
        "\n",
        "        head_dim = embed_dim // query_heads\n",
        "        if not head_dim % 8 == 0:\n",
        "            raise ValueError(\n",
        "                f\"head_dim (embed_dim / num_heads = {head_dim}) must be divisible by 8\"\n",
        "            )\n",
        "        if not head_dim <= 128:\n",
        "            raise ValueError(\n",
        "                f\"head_dim (embed_dim / num_heads = {head_dim}) must be <= 128\"\n",
        "            )\n",
        "\n",
        "        # Query projection layer is the same as in vanilla MHA.\n",
        "        self.q_proj = nn.Linear(\n",
        "            embed_dim, embed_dim, bias=bias, device=device, dtype=dtype\n",
        "        )\n",
        "        # Key/value projection layers have a smaller output dimension, so that\n",
        "        # the we have fewer key/value attention heads after reshaping.\n",
        "        kv_embed_dim = embed_dim // query_heads * kv_heads\n",
        "        self.k_proj = nn.Linear(\n",
        "            embed_dim, kv_embed_dim, bias=bias, device=device, dtype=dtype\n",
        "        )\n",
        "        self.v_proj = nn.Linear(\n",
        "            embed_dim, kv_embed_dim, bias=bias, device=device, dtype=dtype\n",
        "        )\n",
        "        self.norm: Optional[nn.LayerNorm] = None\n",
        "        if layer_norm:\n",
        "            self.norm = nn.LayerNorm(\n",
        "                kv_embed_dim, eps=layer_norm_eps, device=device, dtype=dtype\n",
        "            )\n",
        "\n",
        "        self.out_proj = nn.Linear(\n",
        "            kv_embed_dim, embed_dim, bias=bias, device=device, dtype=dtype\n",
        "        )\n",
        "\n",
        "        self._reset_parameters()\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        nn.init.xavier_normal_(self.q_proj.weight)\n",
        "        if self.q_proj.bias is not None:\n",
        "            nn.init.constant_(self.q_proj.bias, 0)\n",
        "        nn.init.xavier_normal_(self.k_proj.weight)\n",
        "        if self.k_proj.bias is not None:\n",
        "            nn.init.constant_(self.k_proj.bias, 0)\n",
        "\n",
        "        nn.init.xavier_normal_(self.v_proj.weight, gain=self.gamma_init)\n",
        "        if self.v_proj.bias is not None:\n",
        "            nn.init.constant_(self.v_proj.bias, 0)\n",
        "        nn.init.xavier_normal_(self.out_proj.weight, gain=self.gamma_init)\n",
        "        if self.out_proj.bias is not None:\n",
        "            nn.init.constant_(self.out_proj.bias, 0)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        query: Tensor,\n",
        "        key: Tensor,\n",
        "        value: Tensor,\n",
        "        need_weights: bool = False,\n",
        "        # TODO\n",
        "        # attn_mask: Optional[Tensor] = None,\n",
        "        is_causal: bool = False,\n",
        "        average_attn_weights: bool = False,\n",
        "    ) -> Tuple[Tensor, Optional[Tensor]]:\n",
        "        # Notation:\n",
        "        #   b - batch size\n",
        "        #   n - sequence length\n",
        "        #   h - number of heads\n",
        "        #   d - embedding dimension\n",
        "        #\n",
        "        # Input shape: (b, n, d)\n",
        "        q: Tensor = self.q_proj(query)\n",
        "        k: Tensor = self.k_proj(key)\n",
        "        v: Tensor = self.v_proj(value)\n",
        "\n",
        "        # Unfold 'd' dimension into 'h' separate attention heads.\n",
        "        q = rearrange(q, \"b n (h d) -> b n h d\", h=self.query_heads)\n",
        "        k = rearrange(k, \"b n (h d) -> b n h d\", h=self.kv_heads)\n",
        "        v = rearrange(v, \"b n (h d) -> b n h d\", h=self.kv_heads)\n",
        "        # Apply attention, then fold 'h' attention heads back into 'd'.\n",
        "        x, attn = scaled_dot_product_gqa(\n",
        "            query=q,\n",
        "            key=k,\n",
        "            value=v,\n",
        "            # TODO\n",
        "            # mask=attn_mask,\n",
        "            is_causal=is_causal,\n",
        "            need_weights=need_weights,\n",
        "            average_attn_weights=average_attn_weights,\n",
        "            force_grouped=False,\n",
        "        )\n",
        "        x = rearrange(x, \"b n h d -> b n (h d)\")\n",
        "\n",
        "        if self.layer_norm:\n",
        "            assert self.norm is not None\n",
        "            x = self.norm(x)\n",
        "        # Linear projection on attention outputs.\n",
        "        x = self.out_proj(x)\n",
        "\n",
        "        return x, attn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIzuZ3Zuj-Kz"
      },
      "source": [
        "### **GQA Implementation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xkawsqwffVM"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoderLayerGQA(nn.Module):\n",
        "    def __init__(self, embed_dim, query_heads, kv_heads, dim_feedforward=2048):\n",
        "        super().__init__()\n",
        "        # Use special Grouped Query Attention, has the additional kv_heads where kv_heads <= query_heads\n",
        "        self.self_attn = MultiheadGQA(embed_dim, query_heads, kv_heads)\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.linear1 = nn.Linear(embed_dim, dim_feedforward)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, embed_dim)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None,\n",
        "                tgt_key_padding_mask=None, memory_key_padding_mask=None,\n",
        "                tgt_is_causal=False, memory_is_causal=False):\n",
        "        tgt2, _ = self.self_attn(tgt, memory, memory, need_weights=False, is_causal=tgt_is_causal)\n",
        "        tgt = tgt + self.norm1(tgt2)\n",
        "        tgt2 = self.linear2(torch.relu(self.linear1(tgt)))\n",
        "        tgt = tgt + self.norm2(tgt2)\n",
        "        return tgt\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, query_heads, kv_heads, num_decoder_layers, dim_feedforward=2048, max_seq_length=512):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.positional_encoding = nn.Parameter(self._generate_positional_encoding(max_seq_length, embed_dim), requires_grad=False)\n",
        "        self.decoder_layer = TransformerDecoderLayerGQA(embed_dim, query_heads, kv_heads, dim_feedforward)\n",
        "        self.decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=num_decoder_layers)\n",
        "        self.output_layer = nn.Linear(embed_dim, vocab_size)\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def forward(self, tgt):\n",
        "        tgt_seq_length, batch_size = tgt.size(0), tgt.size(1)\n",
        "        tgt_mask = self._generate_square_subsequent_mask(tgt_seq_length).to(tgt.device)\n",
        "\n",
        "        tgt = self.embedding(tgt) * math.sqrt(self.embed_dim)\n",
        "        pos_encoder = self.positional_encoding[:tgt_seq_length, :].unsqueeze(1).expand(-1, batch_size, -1).to(tgt.device)\n",
        "        tgt += pos_encoder\n",
        "\n",
        "        output = self.decoder(tgt, tgt, tgt_mask=tgt_mask)\n",
        "        output = self.output_layer(output)\n",
        "        return output\n",
        "\n",
        "    def _generate_positional_encoding(self, length, embed_dim):\n",
        "        position = torch.arange(length).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, embed_dim, 2) * -(math.log(10000.0) / embed_dim))\n",
        "        pe = torch.zeros(length, embed_dim)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        return pe\n",
        "\n",
        "    def _generate_square_subsequent_mask(self, sz):\n",
        "        return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ps83dyH5jm4w",
        "outputId": "e5720e5c-4c0c-49df-d803-e154e902b562"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Total Loss: 1131.5706059932709, Training Time: 29.454037 seconds\n",
            "Epoch 1, Total Loss: 703.2426543235779, Training Time: 27.433336 seconds\n",
            "Epoch 2, Total Loss: 640.7289428710938, Training Time: 27.352152 seconds\n"
          ]
        }
      ],
      "source": [
        "vocab_size = 5002\n",
        "d_model = 64\n",
        "query_heads = 8\n",
        "kv_heads = 2  # Number of key/value heads in multi-head GQA\n",
        "num_decoder_layers = 4\n",
        "dim_feedforward = 512\n",
        "max_seq_length = 64\n",
        "# no dropout required as it is internally handled by the GQA Attention layer by default\n",
        "\n",
        "model = TransformerModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embed_dim=d_model,\n",
        "    query_heads=query_heads,\n",
        "    kv_heads=kv_heads,\n",
        "    num_decoder_layers=num_decoder_layers,\n",
        "    dim_feedforward=dim_feedforward,\n",
        "    max_seq_length=max_seq_length,\n",
        ")\n",
        "\n",
        "# Loss function\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    start_time = datetime.now()\n",
        "    model.train()  # Set the model to training mode\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        inputs, targets = batch\n",
        "\n",
        "        # Move data to the device\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(inputs)\n",
        "        output = output.reshape(-1, 5002)  # Adjust output dimensions for loss calculation\n",
        "        targets = targets.reshape(-1)\n",
        "\n",
        "        loss = loss_fn(output, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Calculate training duration\n",
        "    end_time = datetime.now()\n",
        "    training_time = (end_time - start_time).total_seconds()\n",
        "\n",
        "    print(f\"Epoch {epoch}, Total Loss: {total_loss}, Training Time: {training_time} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKgSPGV9Dij-"
      },
      "outputs": [],
      "source": [
        "model2 = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAog-4H0_Dtf",
        "outputId": "ade24aa8-71fd-49ce-8111-556d82538e1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has approximately 1013898 trainable parameters.\n"
          ]
        }
      ],
      "source": [
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Approximate model size by counting parameters\n",
        "model_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'The model has approximately {model_parameters} trainable parameters.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0DkFcA2onyg"
      },
      "source": [
        "## **MoD Transformer**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A recent advancement aimed at addressing the scalability challenges of the self-attention layer is the [Mixture of Depths](https://arxiv.org/pdf/2404.02258.pdf) routing. This technique involves a routing layer that learns to select only the top p most effective tokens for processing, with research suggesting that the optimal value for p is 12.5%. Tokens not selected are passed directly to the subsequent layer via a residual connection. This approach increases the number of parameters linearly with n, where n represents the number of tokens in an attention head, but it reduces the computational load by some factor of n^2, enhancing computational efficiency but also learning to pay attention intelligently. The resulting network generally achieves a loss comparable to that of a slower, conventional vanilla network. Typically, this routing is applied every other layer to preserve essential information. In my project, I adapted an implementation by [George Grigorev](https://github.com/thepowerfuldeez/OLMo/blob/main/olmo/mod.py) from GitHub to successfully employ this technique, which significantly accelerated the training process. The implementation uses a MoD wrapper layer which applies the routing before passing the tokens to a standard transformer block."
      ],
      "metadata": {
        "id": "xAoYYTa1reLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Existing Code**"
      ],
      "metadata": {
        "id": "XgclGQv826GS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywhf5gQVWdLU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from datetime import datetime\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "selHGZOLTTPp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class MoD(nn.Module):\n",
        "    \"\"\"The Mixtures of Depth Block that dynamically selects which tokens to process in a block.\n",
        "    Wraps around a decoder block to allow for token dropping, optimizing computational resources.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, block):\n",
        "        super().__init__()\n",
        "        self.block = block  # block is attention + MLP\n",
        "        self.mod_router = nn.Linear(config.d_model, 1, bias=False)\n",
        "        # capacity factor is between [0,1),\n",
        "        # where for 1 we recover a vanilla transformer (i.e., all tokens passed through block)\n",
        "        self.capacity_factor = config.mod_capacity_factor\n",
        "        self.top_k = int(self.capacity_factor * config.max_sequence_length)\n",
        "\n",
        "        # MLP router and BCE loss are used for inference\n",
        "        self.mlp_router = nn.Linear(config.d_model, 1, bias=False)\n",
        "        self.bce_loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.block.reset_parameters()\n",
        "\n",
        "    def set_activation_checkpointing(self, strategy):\n",
        "        self.block.set_activation_checkpointing(strategy)\n",
        "\n",
        "    def get_aux_loss(self, x, targets):\n",
        "        B, T, C = x.shape\n",
        "        mlp_router_logits = self.mlp_router(x.detach().view(B * T, -1))\n",
        "        return self.bce_loss(mlp_router_logits.view(-1), targets)\n",
        "\n",
        "    def forward(self, x, memory=None, **kwargs):\n",
        "        B, T, C = x.shape\n",
        "        top_k = min(self.top_k, int(self.capacity_factor * T))\n",
        "\n",
        "        \"\"\"STEP 1: get logits and top_k tokens\"\"\"\n",
        "        router_logits = self.mod_router(x)\n",
        "        weights, selected_tokens = torch.topk(router_logits, top_k, dim=1, sorted=False)\n",
        "\n",
        "        # 0, if not in topk tokens, 1 else\n",
        "        mlp_targets = torch.zeros_like(router_logits).view(-1)\n",
        "        mlp_targets[selected_tokens.view(-1)] = 1.0\n",
        "        aux_loss = self.get_aux_loss(x, mlp_targets)\n",
        "\n",
        "        # IMPORTANT: need to sort indices to keep causal order for those tokens that\n",
        "        # are processed in a block\n",
        "        selected_tokens, index = torch.sort(selected_tokens, dim=1)\n",
        "        weights = torch.gather(weights, dim=1, index=index)\n",
        "\n",
        "        \"\"\"STEP 2: expand indices to process batches with _reduced_ seqlen\"\"\"\n",
        "        indices_expanded = selected_tokens.expand(-1, -1, C)\n",
        "        top_k_tokens = torch.gather(x, 1, indices_expanded)\n",
        "\n",
        "        # Make sure to pass both 'tgt' and 'memory' to the TransformerDecoderLayer\n",
        "        if memory is None:\n",
        "            memory = top_k_tokens  # Use self-attention if no external memory is provided\n",
        "\n",
        "        top_k_tokens_processed, cache = self.block(top_k_tokens, memory, **kwargs)\n",
        "\n",
        "        \"\"\"STEP 3: combine results\"\"\"\n",
        "        x = torch.scatter_add(\n",
        "            x,\n",
        "            dim=1,\n",
        "            index=indices_expanded,\n",
        "            src=top_k_tokens_processed * weights,\n",
        "        )\n",
        "\n",
        "        return x, cache, aux_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **MoD Implementation**"
      ],
      "metadata": {
        "id": "QQ0JOYBq29jG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2R2Kn_2civ1"
      },
      "outputs": [],
      "source": [
        "# MoD is a wrapper block, therefore we use a Config class to pass all the parameters to the block it wraps\n",
        "\n",
        "class Config:\n",
        "    max_sequence_length = 64\n",
        "    num_tokens = 5002  # vocabulary size\n",
        "    d_model = 64  # dimensionality of the token embeddings\n",
        "    nhead = 8  # number of heads in multi-head attention mechanisms\n",
        "    dim_feedforward = 512  # dimension of the feedforward network model in transformer\n",
        "    dropout = 0.1\n",
        "    num_layers = 4\n",
        "    mod_capacity_factor = 1  # default capacity factor\n",
        "\n",
        "    # the reduced capacity factor (12.5%) is hardcoded here, but later is part of the MoD class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCWPtSAcnH2r"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoderLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(TransformerDecoderLayer, self).__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(config.d_model, config.nhead, dropout=config.dropout)\n",
        "        self.multihead_attn = nn.MultiheadAttention(config.d_model, config.nhead, dropout=config.dropout)\n",
        "        self.linear1 = nn.Linear(config.d_model, config.dim_feedforward)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.linear2 = nn.Linear(config.dim_feedforward, config.d_model)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(config.d_model)\n",
        "        self.norm2 = nn.LayerNorm(config.d_model)\n",
        "        self.norm3 = nn.LayerNorm(config.d_model)\n",
        "        self.dropout1 = nn.Dropout(config.dropout)\n",
        "        self.dropout2 = nn.Dropout(config.dropout)\n",
        "        self.dropout3 = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
        "        tgt2 = self.self_attn(self.norm1(tgt), self.norm1(tgt), self.norm1(tgt), attn_mask=tgt_mask, key_padding_mask=tgt_key_padding_mask)[0]\n",
        "        tgt = tgt + self.dropout1(tgt2)\n",
        "\n",
        "        tgt2 = self.multihead_attn(self.norm2(tgt), self.norm2(memory), self.norm2(memory), attn_mask=memory_mask, key_padding_mask=memory_key_padding_mask)[0]\n",
        "        tgt = tgt + self.dropout2(tgt2)\n",
        "\n",
        "        tgt2 = self.linear2(self.dropout(self.linear1(self.norm3(tgt))))\n",
        "        tgt = tgt + self.dropout3(tgt2)  # Final residual connection\n",
        "\n",
        "        return tgt, None  # Simplified without cache handling\n",
        "\n",
        "class TransformerWithMoD(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(TransformerWithMoD, self).__init__()\n",
        "        self.embedding = nn.Embedding(config.num_tokens, config.d_model)\n",
        "        self.pos_encoder = self.create_positional_encoding(config.max_sequence_length, config.d_model)\n",
        "        # Every other layer has partial routing\n",
        "        self.layers = nn.ModuleList([\n",
        "            MoD(config if i % 2 == 0 else self.modify_config(config, 0.25),\n",
        "                TransformerDecoderLayer(config if i % 2 == 0 else self.modify_config(config, 0.25)))\n",
        "            for i in range(config.num_layers)\n",
        "        ])\n",
        "        self.norm = nn.LayerNorm(config.d_model)\n",
        "        self.final_linear = nn.Linear(config.d_model, config.num_tokens)\n",
        "\n",
        "    def modify_config(self, config, mod_capacity_factor):\n",
        "        # Helper function to modify config inline\n",
        "        config_copy = config.__class__(**{k: v for k, v in vars(config).items()})\n",
        "        setattr(config_copy, 'mod_capacity_factor', mod_capacity_factor)\n",
        "        return config_copy\n",
        "\n",
        "    def create_positional_encoding(self, length, d_model):\n",
        "        \"\"\" Create positional encoding matrix \"\"\"\n",
        "        position = torch.arange(length).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
        "        pos_encoder = torch.zeros(length, d_model)\n",
        "        pos_encoder[:, 0::2] = torch.sin(position * div_term)\n",
        "        pos_encoder[:, 1::2] = torch.cos(position * div_term)\n",
        "        return nn.Parameter(pos_encoder.unsqueeze(0))\n",
        "\n",
        "    def forward(self, src):\n",
        "        src = self.embedding(src) + self.pos_encoder[:, :src.size(1), :]\n",
        "        memory = None\n",
        "\n",
        "        aux_losses = []\n",
        "        for layer in self.layers:\n",
        "            src, cache, aux_loss = layer(src, memory)\n",
        "            aux_losses.append(aux_loss)\n",
        "\n",
        "        src = self.final_linear(self.norm(src))  # Map output to vocab size\n",
        "        return src, sum(aux_losses) / len(aux_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCvI42JFUUTu",
        "outputId": "60bc571d-5686-4112-c57a-3ccec87e863d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Total Loss: 18.27, Auxiliary Loss: 146.61, Training Time: 25.973291 seconds\n",
            "Epoch 2, Total Loss: 18.32, Auxiliary Loss: 146.50, Training Time: 24.655422 seconds\n",
            "Epoch 3, Total Loss: 18.26, Auxiliary Loss: 146.45, Training Time: 24.214063 seconds\n"
          ]
        }
      ],
      "source": [
        "config = Config()\n",
        "model = TransformerWithMoD(config).to(device)\n",
        "vocab_size = config.num_tokens\n",
        "\n",
        "# Loss function\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    start_time = datetime.now()\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_aux_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        inputs, targets = batch\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output, aux_loss = model(inputs)\n",
        "        output = output.reshape(-1, 5002)\n",
        "        targets = targets.reshape(-1)\n",
        "        loss = loss_fn(output, targets)  # Primary loss calculation\n",
        "        total_loss = loss + aux_loss  # Total loss including auxiliary\n",
        "\n",
        "        # Backpropagation\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate losses for logging\n",
        "        total_loss += loss.item()\n",
        "        total_aux_loss += aux_loss.item()\n",
        "\n",
        "    # Calculate training duration\n",
        "    end_time = datetime.now()\n",
        "    training_time = (end_time - start_time).total_seconds()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Total Loss: {total_loss:.2f}, Auxiliary Loss: {total_aux_loss:.2f}, Training Time: {training_time} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnNHDj1iD_aZ"
      },
      "outputs": [],
      "source": [
        "model3 = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j4Evi9mVuLP",
        "outputId": "8a8ef27a-e853-4d1c-a018-c16658309968"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model has approximately 1049098 trainable parameters.\n"
          ]
        }
      ],
      "source": [
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Approximate model size by counting parameters\n",
        "model_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'The model has approximately {model_parameters} trainable parameters.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxlvzCP1Gjf7"
      },
      "source": [
        "## **Frankestein**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since both applications are compatible, I wanted to know if they could be implemented in a single architecture with faster speed or better performance. I decided to create a “Frankenstein” using these. Since MoD accepts any block to wrap, I decided to create a transformer block with GQ Attention instead of multi-head and decided to pass it.\n",
        "\n",
        "Here is a comparison between the standard approach and my hybrid. Standard:\n",
        "\n",
        "\n",
        "```\n",
        "  Input: tokens, original_dim = n\n",
        "  Output: softmax output of dimensions matching vocab_size\n",
        "\n",
        "  For each layer in model_layers:\n",
        "      original_tokens = tokens  # Save the input to the layer for the residual connection\n",
        "      tokens = layer_norm(tokens)  # Normalize the input tokens for the layer\n",
        "\n",
        "      head_outputs = []\n",
        "\n",
        "      For each head in num_heads:\n",
        "          Q = derive_query_matrix(tokens, dim_q)\n",
        "          K = derive_key_matrix(tokens, dim_k)\n",
        "          V = derive_value_matrix(tokens, dim_v)\n",
        "          head_output = attention(Q, K, V)  # Compute attention output\n",
        "          head_outputs.append(head_output)\n",
        "\n",
        "      tokens = concatenate(head_outputs)\n",
        "      tokens = sum(tokens)  # Sum the outputs from all heads\n",
        "      tokens += original_tokens  # Add the residual connection here\n",
        "\n",
        "      tokens = batch_norm(tokens)  # Normalize the combined output\n",
        "      original_tokens_ffn = tokens  # Save the output for the residual connection post-FFN\n",
        "      tokens = FFN(tokens)  # Apply the feed-forward network\n",
        "      tokens += original_tokens_ffn  # Add the residual connection after the FFN\n",
        "\n",
        "  tokens = proj(tokens, dim = vocab_size)  # Project output tokens to vocabulary size\n",
        "  output = softmax(tokens)  # Apply softmax to get probability distribution over vocabulary\n",
        "\n",
        "```\n",
        "\n",
        "Frankenstein Transformer:\n",
        "\n",
        "```\n",
        "Input: tokens, dim = n\n",
        "Output: softmax output of dimensions matching vocab_size\n",
        "\n",
        "For each layer in model_layers:\n",
        "    original_tokens = tokens  # Save the input to the layer for the residual connection\n",
        "\n",
        "    If layer_number % 2 == 0:\n",
        "        tokens = MoD-routing(tokens, p=1)  # Apply MoD-routing with p=1 (full routing) for even layers\n",
        "    Else:\n",
        "        tokens = MoD-routing(tokens, p=0.125)  # Apply MoD-routing with p=0.125 for odd layers\n",
        "\n",
        "    tokens = layer_norm(tokens)  # Normalize the inputs for the layer\n",
        "\n",
        "    head_outputs = []\n",
        "    For each head in num_heads:\n",
        "        Q = derive_query_matrix(tokens, dim_q)\n",
        "        K = derive_key_matrix(tokens, dim_k)\n",
        "        V = derive_value_matrix(tokens, dim_v)\n",
        "        head_output = grouped-query-attention(Q, K, V)  # Grouped-query attention where number of K, V <= Q\n",
        "        head_outputs.append(head_output)\n",
        "\n",
        "    tokens = concatenate(head_outputs)\n",
        "    tokens = sum(tokens)  # Sum the outputs from all heads\n",
        "    tokens += original_tokens  # Add the residual connection after attention sum\n",
        "\n",
        "    tokens = batch_norm(tokens)  # Normalize the combined output\n",
        "    original_tokens_ffn = tokens  # Save the output for the residual connection post-FFN\n",
        "    tokens = FFN(tokens)  # Apply the feed-forward network post normalization\n",
        "    tokens += original_tokens_ffn  # Add the residual connection after the FFN\n",
        "\n",
        "tokens = proj(tokens, dim = vocab_size)  # Project output tokens to vocabulary size\n",
        "output = softmax(tokens)  # Apply softmax to get probability distribution over vocabulary\n",
        "```"
      ],
      "metadata": {
        "id": "ceL9-5rProqG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is one of the first implementations of MoD since it has only come out recently, and the only implementation combining it with GQA."
      ],
      "metadata": {
        "id": "81vgi-vT8XLo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HGLiH_UGnWB"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoderLayerGQA(nn.Module):\n",
        "    def __init__(self, embed_dim, query_heads, kv_heads, dim_feedforward=2048):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiheadGQA(embed_dim, query_heads, kv_heads) # The wrapped block used MultiheadGQA\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.linear1 = nn.Linear(embed_dim, dim_feedforward)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, embed_dim)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None,\n",
        "                tgt_key_padding_mask=None, memory_key_padding_mask=None,\n",
        "                tgt_is_causal=False, memory_is_causal=False):\n",
        "        tgt2, _ = self.self_attn(tgt, memory, memory, need_weights=False, is_causal=tgt_is_causal)\n",
        "        tgt = tgt + self.norm1(tgt2)\n",
        "        tgt2 = self.linear2(F.relu(self.linear1(tgt)))\n",
        "        tgt = tgt + self.norm2(tgt2)\n",
        "        cache = None\n",
        "        return tgt, cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vX3sz1ypKEqg"
      },
      "outputs": [],
      "source": [
        "class Frankenstein(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(Frankenstein, self).__init__()\n",
        "        self.embedding = nn.Embedding(config.num_tokens, config.d_model)\n",
        "        self.pos_encoder = self.create_positional_encoding(config.max_sequence_length, config.d_model)\n",
        "        # Layers wrapped in MoD\n",
        "        self.layers = nn.ModuleList([\n",
        "            MoD(config if i % 2 == 0 else self.modify_config(config, config.mod_reduced),\n",
        "                TransformerDecoderLayerGQA(config.d_model, config.query_heads, config.kv_heads, config.dim_feedforward))\n",
        "            for i in range(config.num_layers)\n",
        "        ])\n",
        "        self.norm = nn.LayerNorm(config.d_model)\n",
        "        self.final_linear = nn.Linear(config.d_model, config.num_tokens)\n",
        "\n",
        "    def modify_config(self, config, mod_capacity_factor):\n",
        "        config_copy = config.__class__(**{k: v for k, v in vars(config).items()})\n",
        "        setattr(config_copy, 'mod_capacity_factor', mod_capacity_factor)\n",
        "        return config_copy\n",
        "\n",
        "    def create_positional_encoding(self, length, d_model):\n",
        "        position = torch.arange(length).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
        "        pos_encoder = torch.zeros(length, d_model)\n",
        "        pos_encoder[:, 0::2] = torch.sin(position * div_term)\n",
        "        pos_encoder[:, 1::2] = torch.cos(position * div_term)\n",
        "        return nn.Parameter(pos_encoder.unsqueeze(0))\n",
        "\n",
        "    def forward(self, src):\n",
        "        src = self.embedding(src) + self.pos_encoder[:, :src.size(1), :]\n",
        "        memory = None\n",
        "\n",
        "        aux_losses = []\n",
        "        for layer in self.layers:\n",
        "            src, cache, aux_loss = layer(src, memory)\n",
        "            aux_losses.append(aux_loss)\n",
        "\n",
        "        src = self.final_linear(self.norm(src))\n",
        "        return src, sum(aux_losses) / len(aux_losses) if aux_losses else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFrDfuUEKHNz"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    max_sequence_length = 64\n",
        "    num_tokens = 5002  # vocabulary size\n",
        "    d_model = 64  # dimensionality of the token embeddings\n",
        "    query_heads = 8  # number of query heads in multi-head attention mechanisms\n",
        "    kv_heads = 8  # number of key/value heads in multi-head attention mechanisms\n",
        "    dim_feedforward = 512  # dimension of the feedforward network model in transformer\n",
        "    num_layers = 4  # number of decoder layers\n",
        "    mod_capacity_factor = 1  # default capacity factor\n",
        "    mod_reduced = 0.125 # This amount of tokens in every other layer will pass through"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cRGFvd-Ytsg",
        "outputId": "2e6205e1-fc92-4241-b20d-69b2a84d2d5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Total Loss: 9.64, Auxiliary Loss: 205.70, Training Time: 25.383059 seconds\n",
            "Epoch 2, Total Loss: 9.55, Auxiliary Loss: 136.74, Training Time: 25.214517 seconds\n",
            "Epoch 3, Total Loss: 8.54, Auxiliary Loss: 139.08, Training Time: 25.533234 seconds\n"
          ]
        }
      ],
      "source": [
        "config = Config()\n",
        "model = Frankenstein(config).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "epochs = 3\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(epochs):\n",
        "    start_time = datetime.now()\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_aux_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        inputs, targets = batch\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output, aux_loss = model(inputs)\n",
        "        output = output.reshape(-1, config.num_tokens)\n",
        "        targets = targets.reshape(-1)\n",
        "        loss = loss_fn(output, targets)\n",
        "        total_loss = loss.item() + aux_loss\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate losses for logging\n",
        "        total_loss += loss.item()\n",
        "        total_aux_loss += aux_loss.item()\n",
        "\n",
        "    # Calculate training duration\n",
        "    end_time = datetime.now()\n",
        "    training_time = (end_time - start_time).total_seconds()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Total Loss: {total_loss:.2f}, Auxiliary Loss: {total_aux_loss:.2f}, Training Time: {training_time} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oe5nQhmhdV4Z"
      },
      "outputs": [],
      "source": [
        "model4 = model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sueaKjioRgPu"
      },
      "source": [
        "## **Comparison**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_2Ylv3WKRnG"
      },
      "source": [
        "### **Part I**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I compared my initial models below based on perplexity scores and times. However, these might not be the most accurate due to slightly different model architectures due to tweaking during debugging each model, so in Part II, I use particular instances of Frankenstein to emulate each of the other architectures. Therefore, those results are better, but this is generally consistent with them, too."
      ],
      "metadata": {
        "id": "hiNawx9Glu5s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QppbgbHfF7JN"
      },
      "outputs": [],
      "source": [
        "# Count number of paramaeters in a model\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def calculate_perplexity(model, data_loader, loss_fn, device, vocab_size):\n",
        "    \"\"\"\n",
        "    Calculate the perplexity of a language model, which measures how well the model predicts a sample.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The trained model to evaluate.\n",
        "        data_loader (DataLoader): DataLoader providing input and target batches.\n",
        "        loss_fn (callable): Loss function used to evaluate model performance.\n",
        "        device (str or torch.device): Device to run the model computations on ('cpu' or 'cuda').\n",
        "        vocab_size (int): The size of the vocabulary, not used in this function directly.\n",
        "\n",
        "    Returns:\n",
        "        float: The perplexity score for the given data.\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()  # Switch the model to evaluation mode (e.g., disable dropout).\n",
        "\n",
        "    total_loss = 0.0  # Initialize total loss accumulated across all batches.\n",
        "    total_items = 0  # Initialize total number of items processed (for averaging loss later).\n",
        "\n",
        "    with torch.no_grad():  # Context manager that disables gradient computation, reducing memory usage and speeding up computations.\n",
        "        for inputs, targets in data_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)  # Move data to the specified device.\n",
        "\n",
        "            outputs = model(inputs)  # Compute the model's output for the given inputs.\n",
        "\n",
        "            if isinstance(outputs, tuple):  # Check if model returns a tuple (e.g., output and hidden states).\n",
        "                outputs = outputs[0]  # If so, use only the logits (first element of tuple) for loss calculation.\n",
        "\n",
        "            outputs = outputs.reshape(-1, vocab_size)  # Flatten the outputs to fit the loss function's requirements.\n",
        "            targets = targets.reshape(-1)  # Flatten the targets accordingly.\n",
        "\n",
        "            loss = loss_fn(outputs, targets)  # Compute the loss between outputs and targets.\n",
        "            total_loss += loss.item() * inputs.size(0)  # Aggregate the loss scaled by batch size for correct averaging.\n",
        "            total_items += inputs.size(0)  # Accumulate the total number of items processed.\n",
        "\n",
        "    average_loss = total_loss / total_items  # Calculate the average loss over all items.\n",
        "    perplexity = torch.exp(torch.tensor(average_loss))  # Compute the perplexity from the average loss.\n",
        "\n",
        "    return perplexity.item()  # Return the perplexity score as a Python float."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBJe7666Ep5a",
        "outputId": "8c8019c4-ad7a-4dd0-843c-31af76737ce9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1 Parameters: 977,290\n",
            "Model 2 Parameters: 1,013,898\n",
            "Model 3 Parameters: 1,049,098\n",
            "Model 4 Parameters: 982,538\n"
          ]
        }
      ],
      "source": [
        "params1 = count_parameters(model1)\n",
        "params2 = count_parameters(model2)\n",
        "params3 = count_parameters(model3)\n",
        "params4 = count_parameters(model4)\n",
        "\n",
        "print(f\"Model 1 Parameters: {params1:,}\")\n",
        "print(f\"Model 2 Parameters: {params2:,}\")\n",
        "print(f\"Model 3 Parameters: {params3:,}\")\n",
        "print(f\"Model 4 Parameters: {params4:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LA94W2iAnDbC",
        "outputId": "2f890bc9-493f-4b8a-b923-5c3e4c26e41e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity of Model 1 (Vanilla Transformer): 48.25\n",
            "Perplexity of Model 2 (GQA): 51.09\n",
            "Perplexity of Model 3 (MOD): 6026.30\n",
            "Perplexity of Model 4 (FRA): 41.73\n"
          ]
        }
      ],
      "source": [
        "# Evaluate perplexity on test data\n",
        "perplexity1 = calculate_perplexity(model1, test_loader, loss_fn, device, vocab_size)\n",
        "perplexity2 = calculate_perplexity(model2, test_loader, loss_fn, device, vocab_size)\n",
        "perplexity3 = calculate_perplexity(model3, test_loader, loss_fn, device, vocab_size)\n",
        "perplexity4 = calculate_perplexity(model4, test_loader, loss_fn, device, vocab_size)\n",
        "\n",
        "# Print results\n",
        "print(f\"Perplexity of Model 1 (Vanilla Transformer): {perplexity1:.2f}\")\n",
        "print(f\"Perplexity of Model 2 (GQA): {perplexity2:.2f}\")\n",
        "# MoD performance is probably weird because of the dataset, earlier when I trained on a dataset from Shakespeare, it's loss was in the same magnitude as the others\n",
        "print(f\"Perplexity of Model 3 (MOD): {perplexity3:.2f}\")\n",
        "print(f\"Perplexity of Model 4 (FRA): {perplexity4:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saX43icqKYYh"
      },
      "source": [
        "### **Part II**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I realized the only way to have a perfect \"control\" architecture would be to compare Frankenstein to itself. Since an MoD router with p = 1 lets all tokens through on all layers, it becomes a standard transformer. Likewise, when the number of key and value matrices are equal to query matrices, a GQ Attention system is essentially standard multi-head attention.\n",
        "I initalized 4 instances of the Frankenstein:\n",
        "- p = 1, KV_Heads = 8 (Standard Implementation)\n",
        "- P = 0.125, KV_Heads = 8 (MoD Implementation)\n",
        "- p = 1, KV_Heads = 2 (GQA Implementation)\n",
        "- p = 0.125, KV_HEADS = 2 (Hybrid Implementation)\n",
        "\n",
        "As can be seen in the results below, which vary a little by data, the hybrid implementation results in faster training than MoD or GQA alone, yet their performance in terms of perplexity is somewhere between MoD's superior performance and GQA's.\n",
        "\n",
        "The speed boost is only occuring when I train on CPUs, while on GPUs the vanilla architecture is typically slightly faster and I am assuming this is since PyTorch and CUDA kernels are optimized for running standard archtectures. It was interesting to learn that these factors that we are blind to can matter; the author of the GQA library mentions that GQA is only marginally faster than a standard transformer on PyTorch because PyTorch \"standard\" implimentations already use in-built techniques like flash attention."
      ],
      "metadata": {
        "id": "5b3384WFn_n0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "aZ3EkbFeKY7Z",
        "outputId": "575edecb-8e00-4c19-e74c-3040e28fa39e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed: KV Heads = 8, Mod Reduced = 1, Time = 278.91 sec, Params = 982538\n",
            "Training completed: KV Heads = 2, Mod Reduced = 1, Time = 281.00 sec, Params = 944906\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-e09529f226d1>\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0maux_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "epochs = 3\n",
        "\n",
        "# Define unique configuration classes\n",
        "class Config1:\n",
        "    max_sequence_length = 64\n",
        "    num_tokens = 5002\n",
        "    d_model = 64\n",
        "    query_heads = 8\n",
        "    kv_heads = 8\n",
        "    dim_feedforward = 512\n",
        "    num_layers = 4\n",
        "    mod_capacity_factor = 1\n",
        "    mod_reduced = 1\n",
        "\n",
        "class Config2:\n",
        "    max_sequence_length = 64\n",
        "    num_tokens = 5002\n",
        "    d_model = 64\n",
        "    query_heads = 8\n",
        "    kv_heads = 2\n",
        "    dim_feedforward = 512\n",
        "    num_layers = 4\n",
        "    mod_capacity_factor = 1\n",
        "    mod_reduced = 1\n",
        "\n",
        "class Config3:\n",
        "    max_sequence_length = 64\n",
        "    num_tokens = 5002\n",
        "    d_model = 64\n",
        "    query_heads = 8\n",
        "    kv_heads = 8\n",
        "    dim_feedforward = 512\n",
        "    num_layers = 4\n",
        "    mod_capacity_factor = 1\n",
        "    mod_reduced = 0.5\n",
        "\n",
        "class Config4:\n",
        "    max_sequence_length = 64\n",
        "    num_tokens = 5002\n",
        "    d_model = 64\n",
        "    query_heads = 8\n",
        "    kv_heads = 2\n",
        "    dim_feedforward = 512\n",
        "    num_layers = 4\n",
        "    mod_capacity_factor = 1\n",
        "    mod_reduced = 0.5\n",
        "\n",
        "configs = [Config1, Config2, Config3, Config4]\n",
        "models = []\n",
        "train_meta = []\n",
        "\n",
        "# Training loop for each configuration class\n",
        "for Config in configs:\n",
        "    model = Frankenstein(Config()).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    start_time = datetime.now()\n",
        "    total_loss = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for inputs, targets in train_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output, aux_loss = model(inputs)\n",
        "            output = output.reshape(-1, Config.num_tokens)\n",
        "            targets = targets.reshape(-1)\n",
        "            loss = loss_fn(output, targets) + aux_loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    training_duration = (datetime.now() - start_time).total_seconds()\n",
        "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    models.append(model)\n",
        "    train_meta.append((training_duration, num_params))\n",
        "\n",
        "    print(f\"Training completed: KV Heads = {Config.kv_heads}, Mod Reduced = {Config.mod_reduced}, Time = {training_duration:.2f} sec, Params = {num_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5YQmAqsLxDm"
      },
      "outputs": [],
      "source": [
        "vocab_size = 5002\n",
        "\n",
        "perplexities = [\n",
        "    calculate_perplexity(models[0], test_loader, loss_fn, device, vocab_size),\n",
        "    calculate_perplexity(models[1], test_loader, loss_fn, device, vocab_size),\n",
        "    calculate_perplexity(models[2], test_loader, loss_fn, device, vocab_size),\n",
        "    calculate_perplexity(models[3], test_loader, loss_fn, device, vocab_size)\n",
        "]\n",
        "\n",
        "model_names = [\"Vanilla Transformer\", \"GQA\", \"MoD\", \"Frankenstein\"]\n",
        "results = []\n",
        "\n",
        "for i, model in enumerate(models):\n",
        "    results.append({\n",
        "        \"Model Name\": model_names[i],\n",
        "        \"Training Time (s)\": train_meta[i][0],\n",
        "        \"Number of Parameters\": train_meta[i][1],\n",
        "        \"Perplexity\": perplexities[i]\n",
        "    })\n",
        "\n",
        "# Print results in a table\n",
        "print(f\"{'Model Name':<20} | {'Training Time (s)':<17} | {'Number of Parameters':<20} | {'Perplexity':<10}\")\n",
        "print(\"-\" * 75)\n",
        "for result in results:\n",
        "    print(f\"{result['Model Name']:<20} | {result['Training Time (s)']:<17.2f} | {result['Number of Parameters']:<20} | {result['Perplexity']:<10.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxvFtlfOHc-w"
      },
      "source": [
        "## **Final Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr1HiqrMacfM"
      },
      "source": [
        "**Architecture**\n",
        "\n",
        "For my final model architecture, I utilized sinusoidal embeddings. I had initially considered using rotary positional embeddings but found them difficult to implement. Additionally, I replaced the standard batch normalization with [root mean square normalization](https://2020machinelearning.medium.com/deep-dive-into-deep-learning-layers-rmsnorm-and-batch-normalization-b2423552be9f), which leads to more stable learning.\n",
        "\n",
        "I encountered significant issues with scaling—surprising, given that I successfully trained a network with disagreement regularization that was 10 layers deep. This was unfortunate, as the primary goal of this exercise was to efficiently train very large networks, but I was able to train one with 4 million parameters. Increasing the number of layers above four resulted in the loss nappearing as nan. Furthermore, the auxiliary loss from the MoD overwhelmingly dominated the actual cross-entropy loss. To achieve stable learning, I decided to normalize the weight initialization and initialize them from a known distribution. I used a scheduler to adjust the learning rates, and crucially, I normalized the auxiliary loss to be approximately on the same scale as the actual loss, ensuring that both the MoD router layers and the network could be trained effectively, leading to stable learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5ztmumd5yJv"
      },
      "outputs": [],
      "source": [
        "class RMSLayerNorm(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements RMS Layer Normalization that normalizes the input features based on the root mean square of\n",
        "    the input minus its mean. This is an alternative to the standard Layer Normalization technique.\n",
        "    \"\"\"\n",
        "    def __init__(self, normalized_shape, eps=1e-5):\n",
        "        \"\"\"\n",
        "        Initialize the RMSLayerNorm module.\n",
        "\n",
        "        Args:\n",
        "            normalized_shape (int or tuple): The shape of the input tensor that should be normalized.\n",
        "                                             This typically corresponds to the features dimension.\n",
        "            eps (float, optional): A small constant (epsilon) added to the denominator for numerical stability.\n",
        "                                   Defaults to 1e-5.\n",
        "        \"\"\"\n",
        "        super().__init__()  # Initialize the parent class (nn.Module)\n",
        "        self.weight = nn.Parameter(torch.ones(normalized_shape))  # Learnable scale parameters\n",
        "        self.bias = nn.Parameter(torch.zeros(normalized_shape))  # Learnable shift parameters\n",
        "        self.eps = eps  # Small constant for numerical stability\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass of the RMS layer normalization.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): The input tensor to be normalized.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: The normalized tensor which is scaled and shifted by learnable parameters.\n",
        "        \"\"\"\n",
        "        mean = x.mean(dim=-1, keepdim=True)  # Compute the mean of the last dimension\n",
        "        squared_mean = (x ** 2).mean(dim=-1, keepdim=True)  # Compute the mean of the squares of the last dimension\n",
        "        rms = torch.sqrt(squared_mean - mean**2 + self.eps)  # Compute the root mean square deviation for normalization\n",
        "        x = (x - mean) / rms  # Normalize the input tensor\n",
        "        return self.weight * x + self.bias  # Scale and shift the normalized tensor and return\n",
        "\n",
        "class TransformerDecoderLayerGQA(nn.Module):\n",
        "    def __init__(self, embed_dim, query_heads, kv_heads, dim_feedforward=2048):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiheadGQA(embed_dim, query_heads, kv_heads) # Use GQA\n",
        "        self.norm1 = RMSLayerNorm(embed_dim)\n",
        "        self.linear1 = nn.Linear(embed_dim, dim_feedforward)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, embed_dim)\n",
        "        self.norm2 = RMSLayerNorm(embed_dim)\n",
        "\n",
        "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None,\n",
        "                tgt_key_padding_mask=None, memory_key_padding_mask=None,\n",
        "                tgt_is_causal=False, memory_is_causal=False):\n",
        "        tgt2, _ = self.self_attn(tgt, memory, memory, need_weights=False, is_causal=tgt_is_causal)\n",
        "        tgt = tgt + self.norm1(tgt2)\n",
        "        tgt2 = self.linear2(F.relu(self.linear1(tgt)))\n",
        "        tgt = tgt + self.norm2(tgt2)\n",
        "        cache = None\n",
        "        return tgt, cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-JeZe1egVtk"
      },
      "outputs": [],
      "source": [
        "# Save and checkpoint model weights\n",
        "def save_model_weights(model, filepath):\n",
        "    torch.save(model.state_dict(), filepath)\n",
        "    print(f\"Model weights saved to {filepath}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvMgKhGomzhm"
      },
      "outputs": [],
      "source": [
        "def init_weights(m):\n",
        "    # Check if the module is a linear layer (fully connected layer)\n",
        "    if isinstance(m, torch.nn.Linear):\n",
        "        # Initialize the weights of the linear layer using Xavier uniform distribution.\n",
        "        # This helps keep the signal in a reasonable range during the initial stages of training.\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        # If the linear layer includes a bias term, initialize it to zero.\n",
        "        if m.bias is not None:\n",
        "            torch.nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    # Check if the module is a layer normalization layer\n",
        "    elif isinstance(m, torch.nn.LayerNorm):\n",
        "        # Initialize the weights of the LayerNorm layer to one.\n",
        "        # This is standard practice to maintain the output's scale as training starts.\n",
        "        torch.nn.init.constant_(m.weight, 1)\n",
        "        # Initialize the bias of the LayerNorm layer to zero.\n",
        "        torch.nn.init.constant_(m.bias, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHsqOUuW744Y",
        "outputId": "8fe806aa-12c9-4350-fe5c-f80b8f0ca51d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 4053.63, Test Loss: 52.29, Training Time: 78.02 seconds\n",
            "Model weights saved to model_epoch_1.pt\n",
            "Epoch 2, Training Loss: 171.71, Test Loss: 38.44, Training Time: 77.55 seconds\n",
            "Model weights saved to model_epoch_2.pt\n",
            "Epoch 3, Training Loss: 145.59, Test Loss: 33.98, Training Time: 77.11 seconds\n",
            "Model weights saved to model_epoch_3.pt\n",
            "Epoch 4, Training Loss: 131.72, Test Loss: 32.80, Training Time: 76.84 seconds\n",
            "Model weights saved to model_epoch_4.pt\n",
            "Epoch 5, Training Loss: 126.56, Test Loss: 31.49, Training Time: 76.74 seconds\n",
            "Model weights saved to model_epoch_5.pt\n",
            "Epoch 6, Training Loss: 123.39, Test Loss: 31.66, Training Time: 76.98 seconds\n",
            "Model weights saved to model_epoch_6.pt\n",
            "Epoch 7, Training Loss: 121.35, Test Loss: 30.63, Training Time: 76.66 seconds\n",
            "Model weights saved to model_epoch_7.pt\n",
            "Epoch 8, Training Loss: 119.71, Test Loss: 30.41, Training Time: 76.63 seconds\n",
            "Model weights saved to model_epoch_8.pt\n",
            "Epoch 9, Training Loss: 118.53, Test Loss: 30.78, Training Time: 76.54 seconds\n",
            "Model weights saved to model_epoch_9.pt\n",
            "Epoch 10, Training Loss: 116.74, Test Loss: 29.79, Training Time: 79.24 seconds\n",
            "Model weights saved to model_epoch_10.pt\n",
            "Epoch 11, Training Loss: 115.55, Test Loss: 29.57, Training Time: 76.49 seconds\n",
            "Model weights saved to model_epoch_11.pt\n",
            "Epoch 12, Training Loss: 114.60, Test Loss: 29.90, Training Time: 76.52 seconds\n",
            "Model weights saved to model_epoch_12.pt\n",
            "Epoch 13, Training Loss: 113.41, Test Loss: 29.85, Training Time: 75.85 seconds\n",
            "Model weights saved to model_epoch_13.pt\n",
            "Epoch 14, Training Loss: 112.71, Test Loss: 29.48, Training Time: 75.88 seconds\n",
            "Model weights saved to model_epoch_14.pt\n",
            "Epoch 15, Training Loss: 111.95, Test Loss: 29.65, Training Time: 76.87 seconds\n",
            "Model weights saved to model_epoch_15.pt\n"
          ]
        }
      ],
      "source": [
        "# Configuration and Model Setup\n",
        "class Config:\n",
        "    # Configuration class for storing model and training parameters\n",
        "    max_sequence_length = 256\n",
        "    num_tokens = 5002\n",
        "    d_model = 256\n",
        "    query_heads = 16\n",
        "    kv_heads = 4\n",
        "    dim_feedforward = 512\n",
        "    num_layers = 4\n",
        "    mod_capacity_factor = 1\n",
        "    mod_reduced = 0.125\n",
        "\n",
        "config = Config()\n",
        "model = Frankenstein(config).to(device)  # Instantiate model with the given configuration and move to device\n",
        "model.apply(init_weights)  # Apply weight initialization using the init_weights function\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)  # Define the loss function and move to the appropriate device\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-4)  # Set up the optimizer with weight decay\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)  # Scheduler for adjusting learning rate\n",
        "\n",
        "import datetime\n",
        "\n",
        "# Parameters\n",
        "epochs = 15\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Determine whether CUDA is available\n",
        "\n",
        "# Training and Evaluation\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "time_list = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    start_time = datetime.datetime.now()  # Record start time of the epoch\n",
        "\n",
        "    # Training phase\n",
        "    model.train()  # Switch model to training mode (enables dropout, batch normalization)\n",
        "    total_train_loss = 0\n",
        "    total_aux_loss = 0\n",
        "    count_batches = 0\n",
        "\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)  # Move data to the correct device\n",
        "        optimizer.zero_grad()  # Clear gradients before each backpropagation\n",
        "        output, aux_loss = model(inputs)  # Forward pass through the model\n",
        "        output = output.reshape(-1, config.num_tokens)\n",
        "        targets = targets.reshape(-1)\n",
        "        loss = loss_fn(output, targets)  # Compute primary loss\n",
        "\n",
        "        # Normalize the auxiliary loss to scale it with the primary loss\n",
        "        mean_primary_loss = total_train_loss / max(count_batches, 1)  # Calculate mean primary loss to avoid zero division\n",
        "        normalized_aux_loss = 0.5 * aux_loss / (mean_primary_loss + 1e-8)  # Add small epsilon to prevent division by zero\n",
        "\n",
        "        combined_loss = loss + normalized_aux_loss  # Combine primary and auxiliary losses\n",
        "\n",
        "        combined_loss.backward()  # Backpropagate the total loss\n",
        "        optimizer.step()  # Update model parameters\n",
        "\n",
        "        total_train_loss += loss.item()  # Aggregate primary loss\n",
        "        total_aux_loss += aux_loss.item()  # Aggregate auxiliary loss\n",
        "        count_batches += 1\n",
        "\n",
        "    scheduler.step(total_train_loss / count_batches)  # Update learning rate based on average primary loss\n",
        "\n",
        "    train_losses.append(total_train_loss)  # Record training loss for this epoch\n",
        "\n",
        "    # Evaluation phase\n",
        "    model.eval()  # Switch model to evaluation mode (disables dropout, batch normalization)\n",
        "    total_test_loss = 0\n",
        "    with torch.no_grad():  # Context manager that disables gradient calculation\n",
        "        for inputs, targets in test_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            output, aux_loss = model(inputs)\n",
        "            output = output.reshape(-1, config.num_tokens)\n",
        "            targets = targets.reshape(-1)\n",
        "            loss = loss_fn(output, targets)\n",
        "            total_test_loss += loss.item()  # Sum up test loss\n",
        "\n",
        "    test_losses.append(total_test_loss)  # Record test loss for this epoch\n",
        "    training_time = (datetime.datetime.now() - start_time).total_seconds()  # Calculate elapsed time for the epoch\n",
        "    time_list.append(training_time)  # Record training time\n",
        "\n",
        "    # Output results for this epoch\n",
        "    print(f\"Epoch {epoch + 1}, Training Loss: {total_train_loss:.2f}, Test Loss: {total_test_loss:.2f}, Training Time: {training_time:.2f} seconds\")\n",
        "\n",
        "    # Save model weights at the end of each epoch\n",
        "    save_model_weights(model, f\"model_epoch_{epoch+1}.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqAaZ2TISTya",
        "outputId": "c71146de-9686-4c1b-dc88-32ab9925b642"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " i would would travelbu pilot pilothesionseciles hous parliamentec liber employrian making tro tro commission effweenaker arran refrane captino westernange athlet planned pun concgeneral jrential automneiance stock inspired target museum ger chap technrovers oper ref\n"
          ]
        }
      ],
      "source": [
        "def generate_text(model, start_sequence, max_length=50, temperature=1.2, top_p=0.9, device='cpu'):\n",
        "    model.eval()  # Switch model to evaluation mode (deactivates dropout layers).\n",
        "    model.to(device)  # Move the model to the specified device (CPU or GPU).\n",
        "    sequence = start_sequence.to(device)  # Transfer the initial input sequence to the specified device.\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculations for efficiency and to prevent memory usage growth.\n",
        "        for _ in range(max_length):  # Generate up to max_length tokens.\n",
        "            output, _ = model(sequence)  # Get the model output for the current sequence and ignore any auxiliary outputs.\n",
        "            logits = output[:, -1, :] / temperature  # Scale the logits by the temperature parameter to adjust \"sharpness\" of the distribution.\n",
        "\n",
        "            # Sort logits to identify the most probable next tokens.\n",
        "            sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "            # Calculate cumulative probabilities for the sorted logits.\n",
        "            cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "\n",
        "            # Eliminate tokens with a cumulative probability higher than top_p, ensuring diversity.\n",
        "            sorted_indices_to_remove = cumulative_probs > top_p\n",
        "            # Shift the mask to the right, keeping the first token that exceeds the threshold.\n",
        "            sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "            sorted_indices_to_remove[..., 0] = 0  # Always keep the most probable token.\n",
        "\n",
        "            indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
        "            logits[:, indices_to_remove] = float('-inf')  # Set removed logits to negative infinity to exclude them.\n",
        "\n",
        "            probabilities = F.softmax(logits, dim=-1)  # Recompute probabilities after modification.\n",
        "            next_token = torch.multinomial(probabilities, 1)  # Sample the next token.\n",
        "\n",
        "            # Append the sampled token to the sequence and ensure it is on the right device.\n",
        "            sequence = torch.cat([sequence, next_token.to(device)], dim=1)\n",
        "            if next_token.item() == eos_token_id:  # Check for the end-of-sequence token.\n",
        "                break\n",
        "\n",
        "    return sequence  # Return the generated sequence.\n",
        "\n",
        "# Usage Example\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Determine the device to use.\n",
        "start_text = \"i\"\n",
        "start_sequence = torch.tensor([dataset.tokenizer.encode(start_text)], dtype=torch.long)  # Prepare initial input sequence.\n",
        "eos_token_id = dataset.tokenizer.word_index.get(\"<EOS>\", -1)  # Retrieve the End-Of-Sequence token ID, with a fallback.\n",
        "\n",
        "# Generate text\n",
        "generated_sequence = generate_text(model, start_sequence, max_length=50, temperature=2, top_p=0.9, device=device)\n",
        "# Convert tensor to CPU, decode it, and clean up the representation.\n",
        "generated_text = ''.join(dataset.tokenizer.decode(generated_sequence.cpu()[0].tolist()))\n",
        "generated_text = generated_text.replace('▁', ' ')  # Replace subword token separator with space for readability.\n",
        "\n",
        "print(generated_text)  # Output the generated text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jny9nTaRVsOg",
        "outputId": "ccb53b23-224b-4949-fae2-a4fcf208ee80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters: 4151690\n"
          ]
        }
      ],
      "source": [
        "def print_num_params(model):\n",
        "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Number of trainable parameters: {total_params}\")\n",
        "\n",
        "# Print the number of trainable parameters\n",
        "print_num_params(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMd4q6aoXAgD",
        "outputId": "b6689585-08c0-49d7-ee47-a5f041825998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity of Model (Frankenstein): 1.04\n"
          ]
        }
      ],
      "source": [
        "perplexity = calculate_perplexity(model, test_loader, loss_fn, device, 5002)\n",
        "\n",
        "# Print results\n",
        "print(f\"Perplexity of Model (Frankenstein): {perplexity:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "im0LkHTSHAyl",
        "outputId": "15992320-69c0-49e7-d805-d2f570907c6d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Set up epoch range\n",
        "epochs = range(1, 16)\n",
        "\n",
        "# Create figure with specific size\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Plot training and test losses on a logarithmic scale\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(epochs, np.log(train_losses), label='Training Loss', marker='o', color='blue')\n",
        "plt.plot(epochs, np.log(test_losses), label='Test Loss', marker='o', color='red')\n",
        "plt.title('Logarithmic Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Log Loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "# Plot training times per epoch\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(epochs, time_list, label='Training Time', marker='o', color='green')\n",
        "plt.title('Training Time Per Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Time (seconds)')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "# Adjust layout and display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Analysis**"
      ],
      "metadata": {
        "id": "UeIdd-7_zz4i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I believe that the inability to train deeper models prevented me from producing a piece of text that was actually legible, as it remained a mess of byte pair encoded tokens. However, there were some patterns in the text, such as \"pilot\" and \"travel\" appearing next to each other. Another likely issue was that at lower temperatures, the model would just repeat itself. This forced me to use higher temperatures, which failed to produce legible text. This is likely why the vanilla transformer, trained for just three epochs on a tinier subset of data, performed nearly as well as the larger model as it did not overfit.\n",
        "\n",
        "\"hectorrirs you sayie:m time too, baby t seasons i't let me th got done..im bet we would be too on falled alongly blue.y could all that man what it, (no\"\n",
        "\n",
        "In fact, the data might be overfit, indicated by the unnaturally low perplexity value of 1.04. I should consider checkpointing the model earlier to see if this leads to improved performance, rather than merely a higher loss."
      ],
      "metadata": {
        "id": "LvdapeD3z2QD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "This was an interesting deep dive into coding simple transformers for the first time and also experimenting and building upon existing literature. It has taught me that architecture is only one of the pillars of a good model; quality of data, hardware optimizations, and training methods are all essential to guaranteeing good performance. I would like to continue learning more about these."
      ],
      "metadata": {
        "id": "p9Oz-ZFLzsRN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Link to Colab Notebook**](https://colab.research.google.com/drive/10AKSUBJvSYvFJeXu2L8WGO6FOBIhr4YE?usp=sharing)\n",
        "\n",
        "[**Model Weights**](https://github.com/MSaadAsad/Projects/blob/main/model_epoch_15.pt)"
      ],
      "metadata": {
        "id": "lFyvKsQ73E3i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Citations**\n",
        "\n",
        "Ainslie, Joshua, et al. “GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints.” arXiv.Org, 23 Dec. 2023, doi.org/10.48550/arXiv.2305.13245.\n",
        "\n",
        "Benistant, Francis. “Deep Dive into Deep Learning: Layers, RMSNorm, and Batch Normalization.” Medium, Medium, 14 Mar. 2024, 2020machinelearning.medium.com/deep-dive-into-deep-learning-layers-rmsnorm-and-batch-normalization-b2423552be9f.\n",
        "\n",
        "Li, Jian, et al. “Multi-Head Attention with Disagreement Regularization.” arXiv.Org, 24 Oct. 2018, doi.org/10.48550/arXiv.1810.10183.\n",
        "\n",
        "Pathak, Kaustubh. “Songs Lyrics.” Kaggle, 23 June 2020, www.kaggle.com/datasets/terminate9298/songs-lyrics.\n",
        "\n",
        "Raposo, David, et al. “Mixture-of-Depths: Dynamically Allocating Compute in Transformer-Based Language Models.” arXiv.Org, 2 Apr. 2024, doi.org/10.48550/arXiv.2404.02258."
      ],
      "metadata": {
        "id": "eB2i_XJpz9h7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AI Statement** GPT was used to research concepts like RMSE Norm and Byte Pair Encodings, and help it guiding me understand model training."
      ],
      "metadata": {
        "id": "_crfTomuz9sn"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ZwHQlKyqtd2r",
        "5rPgX20SnRF4",
        "LjA363JaE_lS",
        "BdAU3qiK6gXq",
        "akqza-CsHgMt",
        "CRiGODMEgmyW",
        "-G9eRrfuj2p0",
        "x0DkFcA2onyg",
        "SxlvzCP1Gjf7",
        "5_2Ylv3WKRnG"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}